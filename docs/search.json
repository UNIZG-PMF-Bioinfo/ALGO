[
  {
    "objectID": "Week2/week2_part2.html",
    "href": "Week2/week2_part2.html",
    "title": "Additional table manipulations",
    "section": "",
    "text": "Important\n\n\n\nAn absolute path always contains the root element and the complete directory list required to locate the file.\n\nD:/User/MyFolder/Algorithms_and_programming/Homework/\n\nA relative path needs to be combined with another path in order to access a file.\n\n../Algorithms_and_programming/Homework/\n\n\n\nWe save the path to a CSV file from the web into a variable called `my_file`. This file will be used for demonstrations throughout the lecture.\n\nmy_file <- \"https://raw.githubusercontent.com/bot13956/datasets/master/introduction_to_physics_grades.csv\"\n\n\n\n\nTab Separated Values (TSV)and Comma Separated Values (CSV). A .tsv file will have tab separated values whereas .csv file has comma separated fields.\n\n\n\n\n\n\n\nNote\n\n\n\nEach function for correctly importing tables contains important arguments such as,\n\nheader - If TRUE then any empty column names are given a name where first data line is a character (non-empty)\nsep - The separator between columns. Most commonly used are ‚Äú;‚Äù, ‚Äú,‚Äù;‚Äú..\nskip - number of rows to remove starting from 0 (default) on the first line\nfill - If TRUE then in case the rows have unequal length, blank fields are implicitly added\ndec - the character used in the file for decimal points\ncol_names - assign new column names (string)\n\nand many others depending on the used function.\n\n\n\n\nReads a file in table format and creates a data frame from it, with cases corresponding to lines and variables to fields in the file.\n\nread.csv( my_file )\n\n\n\n  \n\n\n\n\n\n\nReads a file in table format and creates a data frame from it, with cases corresponding to lines and variables to fields in the file.\n\nread.table( my_file )\n\n\n\n  \n\n\n\n\n\n\nSimilar to read.table but faster and more convenient. All controls such as sep, colClasses and nrows are automatically detected.\n\nfread( my_file )"
  },
  {
    "objectID": "Week2/week2_part2.html#read-non-tabular-data",
    "href": "Week2/week2_part2.html#read-non-tabular-data",
    "title": "Additional table manipulations",
    "section": "Read non-tabular data",
    "text": "Read non-tabular data\nImport data one line at the time\n\nreadLines\n\n# Apply readLines function to txt file\nreadLines(my_file) %>% \n  head()\n\n[1] \"Count,Score,Grade\" \"1,75.0,C\"          \"2,5.0,F\"          \n[4] \"3,20.0,F\"          \"4,87.5,B\"          \"5,100.0,A\"        \n\n\n\n\nread_lines from package readr\n\nreadr::read_lines(my_file) %>% \n  head()\n\n[1] \"Count,Score,Grade\" \"1,75.0,C\"          \"2,5.0,F\"          \n[4] \"3,20.0,F\"          \"4,87.5,B\"          \"5,100.0,A\"        \n\n\n\n\nReading tabular data as a list or a vector\nscan() function can also work when handling data that is stored in simple delimited text files. Unlike the read.table() function, the scan() function returns a list or a vector, not a dataframe.\n\nwhat the type of what gives the type of data to be read. (Here ‚Äòtype‚Äô is used in the sense of typeof.) The supported types are logical, integer, numeric, complex, character, raw and list\n\n\nscan(my_file, sep=\",\", what = \"character\") %>% head\n\n[1] \"Count\" \"Score\" \"Grade\" \"1\"     \"75.0\"  \"C\"    \n\nscan(my_file,sep=\",\",  what=list(\"\", \"\", \"\"), skip = 1) %>% \n  lapply(., function(x) x[1:8])\n\n[[1]]\n[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"\n\n[[2]]\n[1] \"75.0\"  \"5.0\"   \"20.0\"  \"87.5\"  \"100.0\" \"97.5\"  \"95.0\"  \"30.0\" \n\n[[3]]\n[1] \"C\" \"F\" \"F\" \"B\" \"A\" \"A\" \"A\" \"F\""
  },
  {
    "objectID": "Week2/week2_part2.html#saving-data",
    "href": "Week2/week2_part2.html#saving-data",
    "title": "Additional table manipulations",
    "section": "Saving data",
    "text": "Saving data\n\n\n\n\n\n\nNote\n\n\n\nImportant argumnts, my vary depending on the used function\n\nsep - The separator between columns (‚Äú,‚Äù, ‚Äú;‚Äù)\nappend - If TRUE, the file is opened in append mode and column names (header row) are not written. If FALSE, it will overwrite the existing file\nquote - factor fields and column names will only be surrounded by double quotes\ncol.names or row.names - T or F\n\nExamples of how to save data\n\nwrite.table(dt,\"PATH/TO/FILE.csv\", row.names = FALSE)\nwrite.csv(dt,\"PATH/TO/FILE.csv\", row.names = FALSE)\nfwrite(dt, \"PATH/TO/FILE.csv\") \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe fwrite() function from the data.table package is a fast and efficient way to write data tables to disk.\n\n\n\nR data format\n\nSaving a single R object\nYou can save one R object (e.g., a data frame, vector, or model) to a file in RDS format using saveRDS().\n\nsaveRDS(object, file): writes the object to disk.\n\nreadRDS(file): loads the object back into R.\n\nYou can assign the loaded object to any name you like (the original object name is not preserved).\n\n\n# Save a single object to a file\nsaveRDS(my_table, \"my_data.rds\")\n\n# Restore it under a different name\nmy_old_table <- readRDS(\"my_data.rds\")\n\n\n\nSaving multiple R objects (.RData / .rda)\nThe save() function can store one or more R objects together in a single file.\nThese files are usually saved with the extension .RData or .rda.\n\nsave(object1, object2, ..., file = \"name.RData\") ‚Üí saves the specified objects.\n\nload(\"name.RData\") ‚Üí restores all saved objects into the current workspace with their original names.\n\n\n# Save multiple objects\nsave(my_table1, my_table2, file = \"data.RData\")\n# To load the data again\nload(\"data.RData\")\n\n\n\nSaving your entire workspace in a specified file\nIf you want to save everything currently in your R session (all variables, data frames, models, functions, etc.), you can use save.image().\nThis is essentially a shortcut for saving the entire global environment into a single file, usually with the extension .RData.\n\nsave.image(file = \"my_workspace.RData\") ‚Üí saves the entire workspace.\n\nload(\"my_workspace.RData\") ‚Üí restores the full workspace later.\n\n\n# Save everything from the current R session\nsave.image(file = \"my_work_space.RData\")\n# load back the workspace\nload(\"my_work_space.RData\")\n\n\n\n\n\n\n\nTip\n\n\n\nWhile save.image() is convenient, it‚Äôs not always the best choice:\n\nIt can save unnecessary objects, making files very large.\n\nIt may hide dependencies (you won‚Äôt remember later which objects were actually needed).\n\nFor reproducibility, it‚Äôs usually better to save only the objects you need with save() or saveRDS() and rebuild the rest from your script.\n\nRule of thumb:\nUse save.image() for quick backups or temporary sessions, but prefer save() / saveRDS() for clean, shareable projects."
  },
  {
    "objectID": "Week2/week2_part2.html#excel",
    "href": "Week2/week2_part2.html#excel",
    "title": "Additional table manipulations",
    "section": "Excel",
    "text": "Excel\n\nPackage: **readxl**\nThe readxl package is the most common way to import Excel files in R.\nIt has no external dependencies (unlike older packages such as xlsx or XLConnect) and works on all platforms.\n\nSupports both .xls (Excel 97‚Äì2003) and .xlsx (Excel 2007+) formats.\n\nReturns a tibble .\n\nDoes not require Excel or Java to be installed on your computer.\n\nProvides fast, read-only access (you cannot write Excel files with readxl; for that, use openxlsx or writexl).\n\n\nDifference between read_excel, read_xls, and read_xlsx\nAll three functions come from the readxl package.\n\n\n\n\n\n\n\n\nFunction\nSupported format(s)\nNotes\n\n\n\n\nread_excel()\nBoth .xls and .xlsx\nGeneric function, automatically detects file type. Recommended in most cases.\n\n\nread_xls()\nOnly .xls\nWrapper specialized for old Excel files (97‚Äì2003).\n\n\nread_xlsx()\nOnly .xlsx\nWrapper specialized for modern Excel files (2007+).\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn most cases, just use read_excel() ‚Äî it works for both formats and is the most flexible.\n\n\n\n\nExample of manipulation with Excel files\n\n# Read the first sheet by index\nread_excel(\"PATH/TO/EXCEL.xlsx\", sheet = 1)\n\n# Read a sheet by name (\"ATM\" in this case)\nread_excel(\"PATH/TO/EXCEL.xlsx\", sheet = \"ATM\")\n\n# Save the first table into a new Excel file, sheet named \"My_sheet\"\nwrite.xlsx(my_table,\n           file = \"PATH/TO/My_EXCEL.xlsx\",\n           sheetName = \"My_sheet\", \n           col.names = TRUE,\n           row.names = TRUE, \n           append = FALSE)\n\n# Save a second table into the same file, sheet named \"sheet2\"\nwrite.xlsx(my_table2,\n           file = \"PATH/TO/My_EXCEL.xlsx\",\n           sheetName = \"sheet2\",\n           append = TRUE,\n           row.names = FALSE)"
  },
  {
    "objectID": "Week2/week2_part2.html#multiple-files",
    "href": "Week2/week2_part2.html#multiple-files",
    "title": "Additional table manipulations",
    "section": "Multiple files",
    "text": "Multiple files\n\n\n\n\n\n\nImportant\n\n\n\nHow to import multiple files at once?\nUsing list.files function which has the following important arguments:\n\npath - ptah to your folder containing multiple files and subfolders\npattern - regular expression\nfull.names - If TRUE, the directory path is prepended to the file names to give a relative file path.\n\n\n\n\nExample of importing multiple files\nWhat are the data structures of temp and myfiles variables?\n\ntemp <- list.files(path = \"test_data/\", \n                   pattern=\"*.csv\", \n                   full.names = TRUE)\nmyfiles <- lapply(temp, fread)\n\ntemp\n\n[1] \"test_data/breast.csv\"   \"test_data/colon.csv\"    \"test_data/lung.csv\"    \n[4] \"test_data/prostate.csv\"\n\nmyfiles %>% \n  .[1:2]\n\n[[1]]\n   sampleID number_of_mutations type_of_mutation cancer_type\n     <char>               <int>           <char>      <char>\n1:  BRE_001                  89              SNV      Breast\n2:  BRE_002                 165              SNV      Breast\n3:  BRE_003                 110              CNV      Breast\n4:  BRE_004                  20               SV      Breast\n5:  BRE_005                 410              SNV      Breast\n6:  BRE_006                 370              CNV      Breast\n7:  BRE_007                 367              SNV      Breast\n8:  BRE_008                 387              SNV      Breast\n\n[[2]]\n   sampleID number_of_mutations type_of_mutation cancer_type\n     <char>               <int>           <char>      <char>\n1:  COL_001                 418            Indel       Colon\n2:  COL_002                 348              CNV       Colon\n3:  COL_003                 360              CNV       Colon\n4:  COL_004                 259            Indel       Colon\n5:  COL_005                 314            Indel       Colon\n6:  COL_006                 481               SV       Colon\n7:  COL_007                 298               SV       Colon\n8:  COL_008                  24               SV       Colon\n\n\n\n\nList and tables\n\nbase R: do.call\ndo.call() is mostly used with rbind or cbind, but it can apply any function to a list of arguments.\ndo.call(\"any_function\", arguments_list)\ncall(\"any_function\", argument1, argument2)\n\ndo.call(sum, list(1:10))\n\n[1] 55\n\ndo.call(rbind, myfiles)\n\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat is the difference between do.call and lapply?\nlapply() applies a given function for each element in a list, so there will be several function calls.\ndo.call() applies a given function to the list as a whole, so there is only one function call.\n\ndo.call(\"sum\", list(a=1:10, b=2:12))\n\n[1] 132\n\nlapply(list(a=1:10, b=2:12), sum)\n\n$a\n[1] 55\n\n$b\n[1] 77\n\nrbindlist(myfiles)\n\n\n\n  \n\n\n\n\n\n\n\ndata.table: rbindlist\nSame as do.call(‚Äúrbind‚Äù, l) on data.frames, but much faster.\n\nrbindlist(myfiles)\n\n\n\n  \n\n\n\n\n\nConvert any list to table\n\nmy_tb <- fread(my_file)\nmy_tb[, new_col := .GRP,.(Count >=50)]\n\nsplit(my_tb, by=c(\"Grade\", \"new_col\")) %>% .[1:2]\n\n$C.1\n   Count Score  Grade new_col\n   <int> <num> <char>   <int>\n1:     1  75.0      C       1\n2:    13  75.0      C       1\n3:    16  70.0      C       1\n4:    29  70.0      C       1\n5:    47  77.5      C       1\n\n$F.1\n   Count Score  Grade new_col\n   <int> <num> <char>   <int>\n1:     2   5.0      F       1\n2:     3  20.0      F       1\n3:     8  30.0      F       1\n4:    10  37.5      F       1\n5:    12  57.5      F       1\n6:    15  30.0      F       1\n7:    40  50.0      F       1\n8:    43  57.5      F       1\n9:    44  52.5      F       1\n\nsplit(my_tb, list(my_tb$Grade, my_tb$new_col)) %>% .[1:2]\n\n$A.1\n    Count Score  Grade new_col\n    <int> <num> <char>   <int>\n 1:     5 100.0      A       1\n 2:     6  97.5      A       1\n 3:     7  95.0      A       1\n 4:    11 100.0      A       1\n 5:    14  97.5      A       1\n 6:    17 100.0      A       1\n 7:    18  90.0      A       1\n 8:    19  90.0      A       1\n 9:    20  90.0      A       1\n10:    21  97.5      A       1\n11:    22 100.0      A       1\n12:    23  97.5      A       1\n13:    24  90.0      A       1\n14:    28 100.0      A       1\n15:    31 100.0      A       1\n16:    34 100.0      A       1\n17:    45  92.5      A       1\n18:    48  96.3      A       1\n\n$B.1\n   Count Score  Grade new_col\n   <int> <num> <char>   <int>\n1:     4  87.5      B       1\n2:    27  80.0      B       1\n3:    30  85.0      B       1\n4:    38  80.0      B       1\n5:    39  85.0      B       1\n6:    41  80.0      B       1\n7:    46  80.0      B       1\n8:    49  80.0      B       1\n\nsplit(my_tb, list(my_tb$Grade)) %>% .[1:2]\n\n$A\n     Count Score  Grade new_col\n     <int> <num> <char>   <int>\n  1:     5 100.0      A       1\n  2:     6  97.5      A       1\n  3:     7  95.0      A       1\n  4:    11 100.0      A       1\n  5:    14  97.5      A       1\n ---                           \n204:   775  93.0      A       2\n205:   776  90.0      A       2\n206:   778  96.0      A       2\n207:   791  93.0      A       2\n208:   798  99.0      A       2\n\n$B\n     Count Score  Grade new_col\n     <int> <num> <char>   <int>\n  1:     4  87.5      B       1\n  2:    27  80.0      B       1\n  3:    30  85.0      B       1\n  4:    38  80.0      B       1\n  5:    39  85.0      B       1\n ---                           \n208:   790  86.0      B       2\n209:   792  86.0      B       2\n210:   793  81.0      B       2\n211:   794  85.0      B       2\n212:   796  89.0      B       2"
  },
  {
    "objectID": "Week2/week2_part2.html#combining-tables",
    "href": "Week2/week2_part2.html#combining-tables",
    "title": "Additional table manipulations",
    "section": "Combining tables",
    "text": "Combining tables\n\nBinding tables\nHow to ‚Äústitch‚Äù two or more data objects into one?\n\ntb1 <- data.table(sampleID = c(6:1),\n                  cancer = c(\"Breast\",\"Breast\",\"Brain\",\"Liver\",\"Brain\",\"Pancreas\"))\ntb2 <- data.table(sampleID = c(7, 4, 6, 2, 8), \n                  gender = c(\"F\",\"F\",\"M\",\"F\",\"M\")) \nhead(tb1,3)\n\n\n\n  \n\n\nhead(tb2,3)\n\n\n\n  \n\n\n\nFunction rbind() binds the tables by rows. Try run the code below and see what happens. Why is that?\n\nrbind(tb1, tb2)\n\nError in rbindlist(l, use.names, fill, idcol, ignore.attr): Column 2 ['gender'] of item 2 is missing in item 1. Use fill=TRUE to fill with NA (NULL for list columns), or use.names=FALSE to ignore column names.\n\n\n\nrbind(tb1, tb2, fill=TRUE)\n\n\n\n  \n\n\n\nFunction cbind() binds the tables. Do you notice anything strange when you run the code below?\n\ncbind(tb1, tb2)\n\n\n\n  \n\n\n\n\n\nmerge()\n\n\n\n\n\nSpecify by which column you want to merge by and set the argument all= to TRUE to perform the full join\n\nmerge(tb1, tb2, by=\"sampleID\") #if setkey was used prior then merge(tb1,tb2) works the same\n\n\n\n  \n\n\nmerge(tb1, tb2, by=\"sampleID\", all=TRUE)\n\n\n\n  \n\n\n\nRight and left join\n\nmerge(tb1, tb2, by=\"sampleID\", all.x = TRUE)\n\n\n\n  \n\n\nmerge(tb1, tb2, by=\"sampleID\", all.y = TRUE)\n\n\n\n  \n\n\n\n\n\nKEYS\nUse setkey() on data table. This will result in ordered table by the key(s) (columns you have specified) that allows for faster manipulation of data (especially like in merge function!!!)\nSetting a key does two things:\n\nphysically reorders the rows of the data.table by the column(s) provided by reference, always in increasing order.\nmarks those columns as key columns by setting an attribute called sorted to the data.table.\n\nSince the rows are reordered, a data.table can have at most one key because it can not be sorted in more than one way.\nWhat happened in the code chunk below?\n\nsetkey(tb1, sampleID)\nsetkey(tb2, sampleID)\nhead(tb1, 3)\n\n\n\n  \n\n\nhead(tb2,3)\n\n\n\n  \n\n\n\n\ndata.table: [] instead of merge()\nWhat happened here?\n\nsetkey(tb1, sampleID)\nsetkey(tb2, sampleID)\ntb1[tb2]\n\n\n\n  \n\n\ntb2[tb1]\n\n\n\n  \n\n\n\n\n\n\nSummary"
  },
  {
    "objectID": "Week2/week2_part2.html#tidying-the-table",
    "href": "Week2/week2_part2.html#tidying-the-table",
    "title": "Additional table manipulations",
    "section": "Tidying the table",
    "text": "Tidying the table\nTidying a data table often includes renaming columns to make them more informative or consistent.\n\n\n\n\n\n\nTip\n\n\n\nYou can rename columns using names() or colnames().\nnames(dt_cancer) <- vec_names\n\n\n\ndt_cancer <- merge(tb1, tb2, by=\"sampleID\", all=TRUE)\ndt_cancer\n\n\n\n  \n\n\nnames(dt_cancer)[1] <- \"id\"\ndt_cancer\n\n\n\n  \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can rename columns using data.table: setnames\nsetnames(dt_cancer, \"old_names\", \"new_names\")\n\n\n\nnames(dt_cancer)\n\n[1] \"id\"     \"cancer\" \"gender\"\n\nsetnames(dt_cancer,  \"id\", \"sampleID\", skip_absent = TRUE)\nnames(dt_cancer)\n\n[1] \"sampleID\" \"cancer\"   \"gender\"  \n\n\n\nOrdering columns\nSubseting\ndt[,.(col3, col10, col2)]\n\ndt_cancer[,.(gender, sampleID)]\n\n\n\n  \n\n\n\ndata.table: setcolorder()\nsetcolorder(dt_cancer, neworder)\n\ndt_cancer\n\n\n\n  \n\n\nsetcolorder(dt_cancer, c(\"gender\",\"sampleID\"))\ndt_cancer"
  },
  {
    "objectID": "Week2/week2_part2.html#reshaping-the-table",
    "href": "Week2/week2_part2.html#reshaping-the-table",
    "title": "Additional table manipulations",
    "section": "Reshaping the table",
    "text": "Reshaping the table\nYou can create a modified version of an existing data.table by using copy() to avoid changing the original data. Then, use := to add or modify columns by reference.\nIn the example below, we create two new columns (BRCA2 and ATM) filled with random values between 40 and 6000 for 6 rows:\n\ntb.shape <- copy(tb1)\ntb.shape[, \":=\" (\n            BRCA2=sample(40:6000,6),\n            ATM=sample(40:6000,6)) ]\n\ntb.shape\n\n\n\n  \n\n\n\n\nmelt (wide to long)\nConvert DT to long form where money is a separate observation. measure.vars specify the set of columns we would like to collapse (or combine) together.\n\nmelt(tb.shape, id.vars = c(\"sampleID\", \"cancer\"),\n                measure.vars = c(\"BRCA2\", \"ATM\"))\n\n\n\n  \n\n\n\nWe can also specify column indices instead of names.\n\n(tb1.m1  <- melt(tb.shape, \n                 measure.vars = c(\"BRCA2\", \"ATM\"),\n                 variable.name = \"genes\",\n                 value.name = \"n_mutations\")  \n )\n\n\n\n  \n\n\n\n\n\ndcast (long to wide)\nWe want to get the original table from the previous reshaped one using dcast()\n\ndcast(tb1.m1, sampleID + cancer ~ genes, value.var = \"n_mutations\")\n\n\n\n  \n\n\n\n\n\nExercise\nWe are going to do an analysis of mtcars dataset using data.table.\n\nhead(mtcars)\n\n\n\n  \n\n\n\nDo the following:\nConvert mtcars to data.table called mtcars_dt. Add rownames from data.frame to your data.table under the column carnames\n\n# Write solution here\n\nOn the following datasets (dt1 and dt2) perform inner join, left join and outer joins. Do it with merge(), and where you can with []\n\ndt1 <- mtcars_dt[5:25,.(id=carnames, mpg, cyl)]\ndt2 <- mtcars_dt[1:10, .(carnames, gear)]\n\n## Using merge() -----------------\n# Inner Join merge(tb1,tb2) works the same\n# Left Join\n\n# Full Join\n\n\n## Withouth merge() --------------------\n\n# Left Join\n\nCreate a wider table showing the mpg values for cyl vs carnames (Carb)"
  },
  {
    "objectID": "00_main_page.html",
    "href": "00_main_page.html",
    "title": "Algorithms and programming course",
    "section": "",
    "text": "üëã Welcome to the Algorithms and programming course\nThis website hosts the material for the Algorithms and programming course. You‚Äôll find R code examples, tasks, and explanations for each week"
  },
  {
    "objectID": "Week1/week1_lecture1.html",
    "href": "Week1/week1_lecture1.html",
    "title": "Week 1 - Lecture 1",
    "section": "",
    "text": "homeworks + exam\nMoodle forum\nno copy-pasting, no group work\nNO ChatGPT!!\nstudent participation !!!"
  },
  {
    "objectID": "Week1/week1_lecture1.html#r",
    "href": "Week1/week1_lecture1.html#r",
    "title": "Week 1 - Lecture 1",
    "section": "R",
    "text": "R\n\ntoolbox for statistical analyses and data manipulation\nadvanced, flexible data formats\nuser-friendly\nsimple syntax\npackages\ncommunity: documentation, stackOverflow, Github, Biostars‚Ä¶\n\n\nGoogle. Google. Google."
  },
  {
    "objectID": "Week1/week1_lecture1.html#make-your-r-usage-easier",
    "href": "Week1/week1_lecture1.html#make-your-r-usage-easier",
    "title": "Week 1 - Lecture 1",
    "section": "Make your R usage easier",
    "text": "Make your R usage easier\n\nTips&Tricks\n\nCtrl+Enter to run code/send to console\ntab for auto-complete\nkeyboard shortcuts listed in Help\nHistory: send to console, up arrow\nHelp: search manually or from console (?, ??, example())\nadjust defaults in Global options"
  },
  {
    "objectID": "Week1/week1_lecture1.html#make-your-r-usage-easier-1",
    "href": "Week1/week1_lecture1.html#make-your-r-usage-easier-1",
    "title": "Week 1 - Lecture 1",
    "section": "Make your R usage easier",
    "text": "Make your R usage easier\n\nRmarkdown (https://rmarkdown.rstudio.com/)\n\nvarious outputs for sharing your work (.html, .pdf, Word, website‚Ä¶)\ntext + code chunks\nCtrl+Alt+I to insert new chunk\nchunk options (message, warning, fig‚Ä¶)"
  },
  {
    "objectID": "Week1/week1_lecture1.html#make-your-r-usage-easier-2",
    "href": "Week1/week1_lecture1.html#make-your-r-usage-easier-2",
    "title": "Week 1 - Lecture 1",
    "section": "Make your R usage easier",
    "text": "Make your R usage easier\n\nUser interfaces\n\nRGui - useful when upgrading versions (package installR)\nRStudio - additional functionality, projects"
  },
  {
    "objectID": "Week1/week1_lecture1.html#basic-components",
    "href": "Week1/week1_lecture1.html#basic-components",
    "title": "Week 1 - Lecture 1",
    "section": "Basic components",
    "text": "Basic components\n\nvariables\n\nfunctions\n\nenvironment\n\nFor starters, you can use R as a calculator:\n\n3 + 5\n10/2\n4^2\n8 %/% 3\n8 %% 3\n\n[1] 8\n[1] 5\n[1] 16\n[1] 2\n[1] 2\n\n\nSome basic functions:\n\nround(1.86)\nsqrt(25)\nlog10(1000)\n\n[1] 2\n[1] 5\n[1] 3"
  },
  {
    "objectID": "Week1/week1_lecture1.html#variables",
    "href": "Week1/week1_lecture1.html#variables",
    "title": "Week 1 - Lecture 1",
    "section": "Variables",
    "text": "Variables\n\neverything is a vector\n\nassignment:\n\n<-\n<<-\n\n=\nbut don‚Äôt touch the last two!!!\nn <- 5\n\ncreate/collate: c()\n\nview: print() or type name"
  },
  {
    "objectID": "Week1/week1_lecture1.html#vectors",
    "href": "Week1/week1_lecture1.html#vectors",
    "title": "Week 1 - Lecture 1",
    "section": "Vectors",
    "text": "Vectors\n\ncharacter, numeric (integer and double), logical\nclass(), typeof()\nas.x() family of functions\n\nCreate your first variable:\n\nn <- 9\n\nLet‚Äôs see it:\n\nn\nprint(n)\nclass(n)\n\n[1] 9\n[1] 9\n[1] \"numeric\"\n\n\nAs we said, every variable in R is a vector. So what does this mean?\nLet‚Äôs add one more number to our variable n using function c():\n\nn <- c(n, 16); n\nclass(n)\n\n[1]  9 16\n[1] \"numeric\"\n\n\nHow do functions work on this?\n\nsqrt(n)\n\n[1] 3 4\n\n\nWhat happens when we try to add a letter?\n\nn <- c(n, \"z\"); n\nclass(n)\n\n[1] \"9\"  \"16\" \"z\" \n[1] \"character\"\n\n\nNumeric vector:\n\nn1 <- c(1,2,4); n1\nas.character(n1)\n\n[1] 1 2 4\n[1] \"1\" \"2\" \"4\"\n\n\nCreate sequential numeric vector:\n\nn2 <- 1:10; n2\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCharacter vector:\n\nch <- c(\"a\", \"b\", \"c\", \"d\", \"spanishinquisition\"); ch\n\n[1] \"a\"                  \"b\"                  \"c\"                 \n[4] \"d\"                  \"spanishinquisition\""
  },
  {
    "objectID": "Week1/week1_lecture1.html#boolean-variable",
    "href": "Week1/week1_lecture1.html#boolean-variable",
    "title": "Week 1 - Lecture 1",
    "section": "Boolean variable",
    "text": "Boolean variable\nTRUE FALSE\nIt is a binary variable.\n\nbool <- c(T,F,T,T,F); bool\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\nas.numeric(bool)\n\n[1] 1 0 1 1 0\n\nbin <- c(0,1,1,0,1); bin\n\n[1] 0 1 1 0 1\n\nclass(bin)\n\n[1] \"numeric\"\n\nas.logical(bin)\n\n[1] FALSE  TRUE  TRUE FALSE  TRUE"
  },
  {
    "objectID": "Week1/week1_lecture1.html#boolean-operators",
    "href": "Week1/week1_lecture1.html#boolean-operators",
    "title": "Week 1 - Lecture 1",
    "section": "Boolean operators",
    "text": "Boolean operators\n\nAND &\nOR |\nNOT !\n\n\nprint(bool)\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\nprint(bin)\n\n[1] 0 1 1 0 1\n\n\n\n& and | are vectorised\n&& and || are short-circuited\n\n\nbool & bin\nbool && bin\n\n\nbool | bin\nbool || bin\n\n\n!bool\n!bool || bin\n\n\nComparison operators\n==\n!=\n>\n>=\n<\n<=\n\nn2\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nn2 == 2\n\n [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\nn2 > 5\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nn2 >= 5\n\n [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\n\nComparison operators\n\nbool\nbin\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n[1] 0 1 1 0 1\n\n\n\nbool == bin\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\nbool != bin\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n\n\n\nRECYCLING\nWhat happens when vectors are not the same length?\n\nn1; n2\n\n[1] 1 2 4\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nn2*c(2,3)\n\n [1]  2  6  6 12 10 18 14 24 18 30\n\n\n\nn2*n1\n\nWarning in n2 * n1: longer object length is not a multiple of shorter object\nlength\n\nn2 == n1\n\nWarning in n2 == n1: longer object length is not a multiple of shorter object\nlength\n\n\n [1]  1  4 12  4 10 24  7 16 36 10\n [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "Week1/week1_lecture1.html#basic-functions",
    "href": "Week1/week1_lecture1.html#basic-functions",
    "title": "Week 1 - Lecture 1",
    "section": "Basic functions",
    "text": "Basic functions\nlength() : how many elements in a vector\n\nmyvec <- 1:20\nlength(myvec)\n\n[1] 20\n\n\n\nlength(\"banana\")\nnchar(\"banana\")\n\n[1] 1\n[1] 6\n\n\nwhich() : returns positions of elements which satisfy the condition\n\nwhich(n1 == 4)\nwhich((myvec<=2) | (myvec>17))\n\n[1] 3\n[1]  1  2 18 19 20"
  },
  {
    "objectID": "Week1/week1_lecture1.html#basic-functions-1",
    "href": "Week1/week1_lecture1.html#basic-functions-1",
    "title": "Week 1 - Lecture 1",
    "section": "Basic functions",
    "text": "Basic functions\nnames() : gives names to the elements\n\nnames(ch) <- c(\"letter\", \"letter\", \"letter\", \"anotherletter\", \"nobodyexpected\")\nch\n\n              letter               letter               letter \n                 \"a\"                  \"b\"                  \"c\" \n       anotherletter       nobodyexpected \n                 \"d\" \"spanishinquisition\" \n\n\n%in% operator - are elements of the first vector present in the second vector?\n\nn2 %in% n1 \n\n [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "Week1/week1_lecture1.html#basic-functions-2",
    "href": "Week1/week1_lecture1.html#basic-functions-2",
    "title": "Week 1 - Lecture 1",
    "section": "Basic functions",
    "text": "Basic functions\nunique() : returns unique elements\n\nn3 <- c(0,0,0,0,1,1,1,2,2,2,2,2,3,3,3,3,5)\nunique(n3)\n\n[1] 0 1 2 3 5\n\n\nduplicated() : logical: did the same element appear before in the vector?\n\nduplicated(n3)\nduplicated(c(5, n3))\n\n [1] FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n[13] FALSE  TRUE  TRUE  TRUE FALSE\n [1] FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n[13]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\ntable() : how many times does each unique element appear\n\ntable(n3)\n\nn3\n0 1 2 3 5 \n4 3 5 4 1 \n\n\nGet just the frequencies from table:\n\nn3\nas.numeric(table(n3))\n\n [1] 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 5\n[1] 4 3 5 4 1\n\n\nGet unique elements using names - but be careful!\n\nnames(table(n3))\nclass(names(table(n3)))\n\n[1] \"0\" \"1\" \"2\" \"3\" \"5\"\n[1] \"character\"\n\n\n\nTaking a sample\nsample() : take a sample from vector\n\nsample(n3, 4)\nsample(n3, 25, replace=TRUE)\n\n[1] 1 1 2 2\n [1] 1 3 3 3 3 2 3 1 3 3 5 0 3 2 3 0 1 0 0 0 1 2 3 3 0\n\n\nTake a sample from some basic distributions: \n\nsample(1:100, size = 10)\nrunif(10, min=1, max=100)\ns <- rnorm(20, mean=3, sd=0.7); s\n\n [1] 62 67 16 68 26 24 92 44 88 96\n [1] 96.041517 66.758571  9.026198 16.081324 34.776095 43.891385 36.276125\n [8] 45.725790 59.153096 28.156006\n [1] 2.452289 3.428813 2.298833 3.498484 3.189722 3.060816 3.091299 2.592480\n [9] 2.377535 2.659415 3.815378 3.086934 2.620943 3.547611 3.901228 2.643391\n[17] 2.823681 3.576900 2.167666 3.663854\n\n\n\n\nGenerating sequences\nseq()\n\nseq(from=1, to=100, by=2)\nseq(from=0, to=10, length.out=21)\n\n [1]  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49\n[26] 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99\n [1]  0.0  0.5  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0\n[16]  7.5  8.0  8.5  9.0  9.5 10.0\n\n\nrep()\n\nrep(1:3, times=4)\nrep(1:3, each=4)\n\n [1] 1 2 3 1 2 3 1 2 3 1 2 3\n [1] 1 1 1 1 2 2 2 2 3 3 3 3\n\n\ndon‚Äôt mix up rep() and replicate()!\n\nreplicate(n = 10, expr = mean(sample(x = 1:10, size = 3)) )\n\n [1] 7.000000 6.000000 5.000000 7.333333 3.666667 3.666667 7.333333 6.666667\n [9] 6.333333 3.000000\n\n\n\n\nBasic statistics\n\nmean(s)\n\n[1] 3.024863\n\nsd(s)\n\n[1] 0.5371422\n\nquantile(s)\n\n      0%      25%      50%      75%     100% \n2.167666 2.613827 3.073875 3.510765 3.901228"
  },
  {
    "objectID": "Week1/week1_lecture1.html#vector-subsetting",
    "href": "Week1/week1_lecture1.html#vector-subsetting",
    "title": "Week 1 - Lecture 1",
    "section": "Vector subsetting []",
    "text": "Vector subsetting []\n\nby position\nby condition\n\nOne position:\n\nn1[3] \n\n[1] 4\n\n\nMultiple positions:\n\nn2[1:5]\nch[c(2,4,5)]\n\n[1] 1 2 3 4 5\n              letter        anotherletter       nobodyexpected \n                 \"b\"                  \"d\" \"spanishinquisition\" \n\n\nEverything except 1 position:\n\nn2[-7]\n\n[1]  1  2  3  4  5  6  8  9 10\n\n\nPositions stored in another vector:\n\nn2[n1]\n\n[1] 1 2 4"
  },
  {
    "objectID": "Week1/week1_lecture1.html#vector-subsetting-1",
    "href": "Week1/week1_lecture1.html#vector-subsetting-1",
    "title": "Week 1 - Lecture 1",
    "section": "Vector subsetting []",
    "text": "Vector subsetting []\n\nby position\nby condition\n\n\nn2\nn2 > 5\nn2[n2 > 5]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[1]  6  7  8  9 10\n\n\n\nbin\nn2[bin]\nn2[as.logical(bin)]\n\n[1] 0 1 1 0 1\n[1] 1 1 1\n[1]  2  3  5  7  8 10\n\n\n\nExercise 1\nCreate a vector myvec which contains all numbers from 1 to 20 except 3 and 6. Subset fifth and fourth number by position.\n\n\nExercise 2\nSubset myvec to get only numbers smaller or equal to 2 or larger than 17. Return first the numbers, then their positions in the original vector.\nSubset myvec to return only elements which are in positions divisible by 3.\n\n\nExercise 3\nReturn words from vector ch which have more than 5 letters."
  },
  {
    "objectID": "Week1/week1_lecture1.html#data-structures",
    "href": "Week1/week1_lecture1.html#data-structures",
    "title": "Week 1 - Lecture 1",
    "section": "Data structures",
    "text": "Data structures\n- vectors  \n- factors = vectors with (unchangeable) levels  \n- matrices = dataframes with 1 type of data  \n- lists  \n- data frames = pretty lists"
  },
  {
    "objectID": "Week1/week1_lecture1.html#factors",
    "href": "Week1/week1_lecture1.html#factors",
    "title": "Week 1 - Lecture 1",
    "section": "Factors",
    "text": "Factors\nVectors with predefined levels.\nUsual suspects for your errors.\n\nfac <- factor(n3); fac\n\n [1] 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 5\nLevels: 0 1 2 3 5\n\n\n\nfac[1] <- 6\n\nWarning in `[<-.factor`(`*tmp*`, 1, value = 6): invalid factor level, NA\ngenerated\n\nfac\n\n [1] <NA> 0    0    0    1    1    1    2    2    2    2    2    3    3    3   \n[16] 3    5   \nLevels: 0 1 2 3 5\n\n\nSo how to turn a factor into normal numeric vector? There‚Äôs a hack.\n\nas.numeric(fac)\nas.numeric(as.character(fac))\n\n [1] NA  1  1  1  2  2  2  3  3  3  3  3  4  4  4  4  5\n [1] NA  0  0  0  1  1  1  2  2  2  2  2  3  3  3  3  5"
  },
  {
    "objectID": "Week1/week1_lecture1.html#matrices",
    "href": "Week1/week1_lecture1.html#matrices",
    "title": "Week 1 - Lecture 1",
    "section": "Matrices",
    "text": "Matrices\n\nm <- matrix(1:15, nrow=5, ncol=3); m\n\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n\n\nSubsetting:\n\nm[1,3]\nm[12]\nm[,2]\n\n[1] 11\n[1] 12\n[1]  6  7  8  9 10\n\n\nBasic functions:\n\nt(m)      # transpose\ndiag(m)   # extract diagonal\ndim(m)    # see dimensions\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    2    3    4    5\n[2,]    6    7    8    9   10\n[3,]   11   12   13   14   15\n[1]  1  7 13\n[1] 5 3\n\n\n\nExercise 4\nMake a 4x4 matrix m2 with numbers from 1 to 16. Let the first row be: 1 2 3 4 (hint: consult help with ?matrix).\nChange all the numbers on the diagonal to zeroes.\nSum the elements in each row."
  },
  {
    "objectID": "Week1/week1_lecture1.html#lists",
    "href": "Week1/week1_lecture1.html#lists",
    "title": "Week 1 - Lecture 1",
    "section": "Lists",
    "text": "Lists\nStore anything; most flexible data type.\n\nl <- list(n2, bool, m, fac); l\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[2]]\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n[[3]]\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n\n[[4]]\n [1] <NA> 0    0    0    1    1    1    2    2    2    2    2    3    3    3   \n[16] 3    5   \nLevels: 0 1 2 3 5"
  },
  {
    "objectID": "Week1/week1_lecture1.html#lists-1",
    "href": "Week1/week1_lecture1.html#lists-1",
    "title": "Week 1 - Lecture 1",
    "section": "Lists",
    "text": "Lists\nLet‚Äôs name the entries:\n\nnames(l) <- c(\"vector1\", \"vector2\", \"matrix1\", \"factor1\")\n\nHow many entries?\n\nlength(l)\n\n[1] 4\n\n\nHow about dimensions?\n\ndim(l)\n\nNULL\n\n\n\nList subsetting\nBy position:\n\nl[2]\nclass(l[2])\n\n$vector2\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n[1] \"list\"\n\n\nBy position, another way:\n\nl[[4]]\nclass(l[[4]])\n\n [1] <NA> 0    0    0    1    1    1    2    2    2    2    2    3    3    3   \n[16] 3    5   \nLevels: 0 1 2 3 5\n[1] \"factor\"\n\n\nBy name:\n\nl$vector2\nclass(l$vector2)\nl[[\"factor1\"]]\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n[1] \"logical\"\n [1] <NA> 0    0    0    1    1    1    2    2    2    2    2    3    3    3   \n[16] 3    5   \nLevels: 0 1 2 3 5\n\n\nSubset an element of an element:\n\nunlist(l[2])\n\nvector21 vector22 vector23 vector24 vector25 \n    TRUE    FALSE     TRUE     TRUE    FALSE \n\nclass(unlist(l[2]))\n\n[1] \"logical\"\n\nl[3]\n\n$matrix1\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n\nl[[3]][2,3]\n\n[1] 12\n\n#l[3][2,3]"
  },
  {
    "objectID": "Week1/week1_lecture1.html#data-frames",
    "href": "Week1/week1_lecture1.html#data-frames",
    "title": "Week 1 - Lecture 1",
    "section": "Data frames",
    "text": "Data frames\n‚ÄúMatrices‚Äù with different types of data.\n\ndf <- data.frame(m, ch); df\n\n\n\n  \n\n\ndim(df)\n\n[1] 5 4\n\nncol(df); nrow(df)\n\n[1] 4\n\n\n[1] 5\n\ncolnames(df); rownames(df)\n\n[1] \"X1\" \"X2\" \"X3\" \"ch\"\n\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\n\nData frame subsetting\nBy position:\n\ndf[2, 3]\ndf[, 3:4]\n\n[1] 12\n\n\n\n\n  \n\n\n\nBy names:\n\ndf[\"ch\"]\ndf$ch\nclass(df[\"ch\"])\nclass(df$ch)\n\n\n\n  \n\n\n\n[1] \"a\"                  \"b\"                  \"c\"                 \n[4] \"d\"                  \"spanishinquisition\"\n[1] \"data.frame\"\n[1] \"character\"\n\n\nInternally, data frames are lists with entries of equal lengths."
  },
  {
    "objectID": "Week1/week1_lecture1.html#data-frames-1",
    "href": "Week1/week1_lecture1.html#data-frames-1",
    "title": "Week 1 - Lecture 1",
    "section": "Data frames",
    "text": "Data frames\nAdding a column:\n\ndf <- cbind(df, bool); df\n\n\n\n  \n\n\n\nRemoving a column:\n\ndf[\"bool\"] <- NULL; df\n\n\n\n  \n\n\n\nRemoving a row:\n\n#df[5, ] <- NULL; df\n\ndf <- df[-5, ]\n\n\nExercise 5\nR has a number of pre-loaded datasets, iris probably being the most famous one.\nLoad iris and calculate mean length of sepal."
  },
  {
    "objectID": "Week1/week1_lecture2.html",
    "href": "Week1/week1_lecture2.html",
    "title": "Week 1 - Lecture 2",
    "section": "",
    "text": "myfun <- function(input, parameters) {\ndo a thing\ndo another thing\n‚Ä¶\noutput\n}\nWrite a function\nMake a simple function which will multiplies two numbers.\n\nmySimpleFun <- function(a=1,b) {\n    product <- a*b\n    return(product)\n}\n\nThe function will return whatever is called on the last line, or you can explicitly state it with return().\nExecution i.e.¬†calling a function\n\nmySimpleFun(b=3)\n\n[1] 3\n\nmySimpleFun(a=2, b=3)\n\n[1] 6\n\nmySimpleFun(2, 3)\n\n[1] 6"
  },
  {
    "objectID": "Week1/week1_lecture2.html#global-and-local-variables",
    "href": "Week1/week1_lecture2.html#global-and-local-variables",
    "title": "Week 1 - Lecture 2",
    "section": "Global and local variables",
    "text": "Global and local variables\n\nmySimpleFun <- function(a=1,b) {\n    product <- a*b\n    return(product)\n}\n\nWhat happens with the function if we change variable vol outside it? Nothing! The function has its own local environment.\n\nproduct <- 5\nmySimpleFun(2, 3)\n\n[1] 6\n\nproduct\n\n[1] 5"
  },
  {
    "objectID": "Week1/week1_lecture2.html#function-as-binary-operator",
    "href": "Week1/week1_lecture2.html#function-as-binary-operator",
    "title": "Week 1 - Lecture 2",
    "section": "Function as binary operator",
    "text": "Function as binary operator\nAll functions are beautiful, but not all come in the same shape :)\nAn operator is a function that takes one or two arguments and can be written without parentheses\nfunction(arg1, arg2)\nvs.\narg1 operator arg2\nOperator %in% is used to identify if an element belongs to a vector or dataframe.\n\nc(1,4,2,1) %in% c(2,3)\n\n[1] FALSE FALSE  TRUE FALSE"
  },
  {
    "objectID": "Week1/week1_lecture2.html#multiple-inputs-vectorisation",
    "href": "Week1/week1_lecture2.html#multiple-inputs-vectorisation",
    "title": "Week 1 - Lecture 2",
    "section": "Multiple inputs / vectorisation",
    "text": "Multiple inputs / vectorisation\n\nmySimpleFun(1:3, 3:5)\n\n[1]  3  8 15"
  },
  {
    "objectID": "Week1/week1_lecture2.html#flow-control-if-statement",
    "href": "Week1/week1_lecture2.html#flow-control-if-statement",
    "title": "Week 1 - Lecture 2",
    "section": "Flow control: if statement",
    "text": "Flow control: if statement\nif(condition is fulfilled) {\ndo the thing\n} else {\ndo the other thing\n}\n\nmySimpleFun <- function(a=1,b) {\n    if (a < 0) {\n        a <- (-1)*a\n    } else {\n        a <- a\n    }\n    \n    product <- a*b\n    return(product)\n}"
  },
  {
    "objectID": "Week1/week1_lecture2.html#warnings-errors-and-messages",
    "href": "Week1/week1_lecture2.html#warnings-errors-and-messages",
    "title": "Week 1 - Lecture 2",
    "section": "Warnings, errors and messages",
    "text": "Warnings, errors and messages\nYou are getting the hang of this, and with an additional pair of hands the work is coming along quickly. But after one calculation, you notice the numbers are fishy. Upon closer inspection, you discover that you input thickness with a decimal dot in the wrong place. To prevent this from happening again and going unnoticed, you add a warning():\n\nmySimpleFun <- function(a=1,b) {\n    if (a < 0) {\n        warning(\"First number is negative! Changing it to positive.\")\n        a <- (-1)*a\n    } else {\n        a <- a\n    }\n    \n    product <- a*b\n    return(product)\n}\n\nIf you want the function to stop executing, use break().\nmessage() has similar syntax but different ‚Äúlevel of alert‚Äù."
  },
  {
    "objectID": "Week1/week1_lecture2.html#multiple-outputs",
    "href": "Week1/week1_lecture2.html#multiple-outputs",
    "title": "Week 1 - Lecture 2",
    "section": "Multiple outputs",
    "text": "Multiple outputs\n\nmySimpleFun <- function(a=1,b) {\n    if (a < 0) {\n        warning(\"First number is negative! Changing it to positive.\")\n        a <- (-1)*a\n    } else {\n        a <- a\n    }\n    # calculate product\n    product <- a*b\n    # make a figure\n    figure <-  plot(c(a,b))\n    # save a list\n    res_list <- list(\"product\"=product, \"figure\"=figure)\n    # return\n    return(res_list)\n}\n## run the fuction\nmySimpleFun(b=-2)\n\n\n\n\n$product\n[1] -2\n\n$figure\nNULL\n\n\nifelse(test, yes, no) - vectorised\n\nmySimpleFun <- function(a=1,b) {\n  # make all negatives positive\n  a <- ifelse(a < 0, -a, a)\n\n  # calculate product\n  product <- a * b\n\n  # (plots will only show the last one in a loop, so you usually don‚Äôt do this inside)\n  plot(a, b)   # e.g. scatter plot\n\n  list(product = product)\n}\n\nmySimpleFun(a= c(2,3,2,-1), b=c(3,4,5,2))\n\n\n\n\n$product\n[1]  6 12 10  2\n\n\nTry to change ‚Äòlist‚Äô with ‚Äòc‚Äô and see what happens. You have to put multiple outputs together as a list, otherwise it doesn‚Äôt work properly!"
  },
  {
    "objectID": "Week1/week1_lecture2.html#looping-in-r",
    "href": "Week1/week1_lecture2.html#looping-in-r",
    "title": "Week 1 - Lecture 2",
    "section": "Looping in R",
    "text": "Looping in R\nfor(each value in sequence) {\ndo the thing\n}\n\nfor(i in 1:5) {\n    print(\"bla\")\n}\n\n[1] \"bla\"\n[1] \"bla\"\n[1] \"bla\"\n[1] \"bla\"\n[1] \"bla\"\n\n\nwhile(condition is true) {\ndo the thing\n}\nrepeat {\nthe thing\nif(condition is true) { break }\n}\nIt‚Äôs NEVER a time for a loop in R. Instead, there‚Äôs the apply() family of functions:"
  },
  {
    "objectID": "Week1/week1_lecture2.html#apply-family-of-functions",
    "href": "Week1/week1_lecture2.html#apply-family-of-functions",
    "title": "Week 1 - Lecture 2",
    "section": "Apply family of functions",
    "text": "Apply family of functions\nlapply():\n\nlapply(iris[, 1:4], sum)          # preforms a function over each list element\n\n$Sepal.Length\n[1] 876.5\n\n$Sepal.Width\n[1] 458.6\n\n$Petal.Length\n[1] 563.7\n\n$Petal.Width\n[1] 179.9\n\nclass(lapply(iris[, 1:4], sum))   # returns a list\n\n[1] \"list\"\n\n\nNotice the three dots (ellipsis) in function description: lapply(X, FUN, ...)\nAccess list entries explicitly by using function(x):\n\nlapply(iris[, 1:4], function(x) sqrt(x[20:30]))\n\n$Sepal.Length\n [1] 2.258318 2.323790 2.258318 2.144761 2.258318 2.190890 2.236068 2.236068\n [9] 2.280351 2.280351 2.167948\n\n$Sepal.Width\n [1] 1.949359 1.843909 1.923538 1.897367 1.816590 1.843909 1.732051 1.843909\n [9] 1.870829 1.843909 1.788854\n\n$Petal.Length\n [1] 1.224745 1.303840 1.224745 1.000000 1.303840 1.378405 1.264911 1.264911\n [9] 1.224745 1.183216 1.264911\n\n$Petal.Width\n [1] 0.5477226 0.4472136 0.6324555 0.4472136 0.7071068 0.4472136 0.4472136\n [8] 0.6324555 0.4472136 0.4472136 0.4472136"
  },
  {
    "objectID": "Week1/week1_lecture2.html#apply-family-of-functions-1",
    "href": "Week1/week1_lecture2.html#apply-family-of-functions-1",
    "title": "Week 1 - Lecture 2",
    "section": "Apply family of functions",
    "text": "Apply family of functions\nsapply() : lapply, but tries to return simpler data format\n\nsapply(iris[, 1:4], sum)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n       876.5        458.6        563.7        179.9 \n\nclass(sapply(iris[, 1:4], sum))\n\n[1] \"numeric\""
  },
  {
    "objectID": "Week1/week1_lecture2.html#apply-family-of-functions-2",
    "href": "Week1/week1_lecture2.html#apply-family-of-functions-2",
    "title": "Week 1 - Lecture 2",
    "section": "Apply family of functions",
    "text": "Apply family of functions\napply() : apply function over margins of array (1 for rows, 2 for columns)\n\napply(iris[, 1:4], 1, sum)\n\n  [1] 10.2  9.5  9.4  9.4 10.2 11.4  9.7 10.1  8.9  9.6 10.8 10.0  9.3  8.5 11.2\n [16] 12.0 11.0 10.3 11.5 10.7 10.7 10.7  9.4 10.6 10.3  9.8 10.4 10.4 10.2  9.7\n [31]  9.7 10.7 10.9 11.3  9.7  9.6 10.5 10.0  8.9 10.2 10.1  8.4  9.1 10.7 11.2\n [46]  9.5 10.7  9.4 10.7  9.9 16.3 15.6 16.4 13.1 15.4 14.3 15.9 11.6 15.4 13.2\n [61] 11.5 14.6 13.2 15.1 13.4 15.6 14.6 13.6 14.4 13.1 15.7 14.2 15.2 14.8 14.9\n [76] 15.4 15.8 16.4 14.9 12.8 12.8 12.6 13.6 15.4 14.4 15.5 16.0 14.3 14.0 13.3\n [91] 13.7 15.1 13.6 11.6 13.8 14.1 14.1 14.7 11.7 13.9 18.1 15.5 18.1 16.6 17.5\n[106] 19.3 13.6 18.3 16.8 19.4 16.8 16.3 17.4 15.2 16.1 17.2 16.8 20.4 19.5 14.7\n[121] 18.1 15.3 19.2 15.7 17.8 18.2 15.6 15.8 16.9 17.6 18.2 20.1 17.0 15.7 15.7\n[136] 19.1 17.7 16.8 15.6 17.5 17.8 17.4 15.5 18.2 18.2 17.2 15.7 16.7 17.3 15.8"
  },
  {
    "objectID": "Week1/week1_lecture2.html#apply-family-of-functions-3",
    "href": "Week1/week1_lecture2.html#apply-family-of-functions-3",
    "title": "Week 1 - Lecture 2",
    "section": "Apply family of functions",
    "text": "Apply family of functions\nreplicate() : repeated evaluation of expression; returns an array\n\nreplicate(3, sample(1:10, 5))\n\n     [,1] [,2] [,3]\n[1,]    5    8    6\n[2,]    9    2    9\n[3,]    1    4    3\n[4,]    4    7    2\n[5,]    8   10   10"
  },
  {
    "objectID": "Week1/week1_lecture2.html#take-home-messages-on-writing-your-own-functions",
    "href": "Week1/week1_lecture2.html#take-home-messages-on-writing-your-own-functions",
    "title": "Week 1 - Lecture 2",
    "section": "Take home messages on writing your own functions",
    "text": "Take home messages on writing your own functions\nTake care of the future user of your function - it‚Äôll probably be you.\n\ntidy and clear commands - avoid salami code\ntidy and logical higher structures - avoid spaghetti code\nsensible function and variable names\n(b, bb, bbs, dajproradivise, omg, matfixmerggr)\nCOMMENT YOUR CODE\n\n\n# example of salami code:\nsum(as.numeric(names(table(sample(50:300, 1000, replace=T) %/% 25))))   \n\n[1] 77\n\n\nvs.\n\nmysample <- sample(50:300, 1000, replace=T)\nroundit <- mysample %/% 25\ntb <- table(roundit)\ntb\n\nroundit\n  2   3   4   5   6   7   8   9  10  11  12 \n 89  92  97 101  97 104 103 107  95 109   6 \n\ncategories <- as.numeric(names(tb))\ncategories\n\n [1]  2  3  4  5  6  7  8  9 10 11 12\n\ncat_sum <- sum(categories)\ncat_sum\n\n[1] 77\n\n\nMost importantly, if there is already a function for what you are trying to do, don‚Äôt write your own without a good reason. (Homework instructions are a good reason.)"
  },
  {
    "objectID": "Week2/week2_part0.html",
    "href": "Week2/week2_part0.html",
    "title": "R packages",
    "section": "",
    "text": "CRAN is the official repository for R packages. It hosts thousands of stable, peer-reviewed R packages that have passed strict checks for quality and compatibility.\n\n#Install from CRAN as follow:\ninstall.packages(\"magrittr\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\") \n\n\n\n\nGitHub is a platform for code sharing and collaboration, widely used by developers. Many R package authors share their development versions on GitHub‚Äîthese might include the newest features or bug fixes that haven‚Äôt yet been submitted to CRAN.\n\n#Or, install the latest version from GitHub as follow:\n# Install\nif(!require(devtools)) install.packages(\"devtools\")\ndevtools::install_github(\"kassambara/ggpubr\")\n\n\n\n\nBioconductor is a specialized repository for packages focused on bioinformatics, genomics, and computational biology. It includes tools for analyzing DNA/RNA sequencing, gene expression, and other biological data.\n\n## Bioconductor\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"airway\")"
  },
  {
    "objectID": "Week2/week2_part0.html#load-the-packages",
    "href": "Week2/week2_part0.html#load-the-packages",
    "title": "R packages",
    "section": "Load the packages",
    "text": "Load the packages\nWhen you install a package in R (using install.packages() or similar), you‚Äôre downloading it and saving it to your computer. This only needs to be done once (per R environment).\nHowever, to use the functions or data from a package in your current R session, you must load the package with library() or require().\n\nlibrary(\"magrittr\")\nlibrary(\"data.table\")\nlibrary(\"ggpubr\")\n\n\nPipes ( %>% )\nPackage magrittr provides a new ‚Äúpipe‚Äù-like operator, %>%. The pipe operator allows you to pipe a value forward into a function. For example you can write vec %>% sum instead of sum(vec) . It makes your code more intuitive to read and write especially when ‚Äúpipping/chaining‚Äù multiple arguments.\n\nsample(x = 1:1000, size = 40) %>% \n   # Call function sum on the whole vector"
  },
  {
    "objectID": "Week2/week2_part1.html",
    "href": "Week2/week2_part1.html",
    "title": "Table manipulation",
    "section": "",
    "text": "A data.frame is a 2D table-like structure where columns can hold different data types. data.table is an enhanced version of data.frame that provides faster and more memory-efficient operations.\n\n\n\n\n\n\nBuilt-in datasets\n\n\n\n\nR comes with several built-in datasets that are useful for learning, testing, and demonstrating functions without needing to load external data.\nThese datasets are included in base R and standard packages like datasets, and can be accessed directly by name (e.g., CO2, iris, mtcars, etc.).\n\n\n\nWe will be working with build-in dataset iris introduced by Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems, contains three plant species (setosa, virginica, versicolor) and four features measured for each sample.\nLet‚Äôs examine the first six rows of the table!\n\n# Call the table\nhead(iris) \n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nFeature\ndata.frame\ndata.table\n\n\n\n\nBase structure\nBase R object\nExtension of data.frame\n\n\nSpeed\nModerate\nVery fast, optimized for large data\n\n\nSyntax\nVerbose\nConcise and powerful\n\n\nRownames\nSupported\nDiscouraged / ignored\n\n\nMemory usage\nStandard\nMore memory-efficient\n\n\nGrouping\nUses aggregate() or dplyr\nBuilt-in with by=\n\n\nJoining\nUses merge()\nFast joins with keys (setkey())\n\n\nLearning curve\nLow (familiar to most R users)\nMedium (different syntax)\n\n\n\n\n\n\n\n\n\n\n\nFunctions to import the data\n\n\n\n\nbasic R import function:\ndf <- read.csv()\ndf <- read.tsv()\ndf <- read.table()\ndata.table import function:\ndt <- fread()\nusing specialized funcions from R packages to import files such as Excel, SPSS\ndf <- read_excel()\ndf <- read.spss()\n..."
  },
  {
    "objectID": "Week2/week2_part1.html#how-to-obtain-data.table",
    "href": "Week2/week2_part1.html#how-to-obtain-data.table",
    "title": "Table manipulation",
    "section": "How to obtain data.table?",
    "text": "How to obtain data.table?\n\n\n\n\n\n\nImport as data.table or convert existing formats to data.table\n\n\n\n\nImport data using function fread().\n\ndt_import <- fread(\"PATH/TO/FILE\")\n\nConvert data.frame (even other objects such as matrices, GRanges object‚Ä¶) using as.data.table().\n\ndt_import <- as.data.table(df)\n\nAnother approach of converting object to data.table using setDT() but without defining the new variable.\n\nsetDT(df)\n\n\n\n\n\n\n\n\nTip\n\n\n\nA file path tells R where to find or save a file.\n\nAbsolute path: The full location starting from the root of your computer.\n\nExample: \"C:/Users/Paula/Documents/data.csv\"\n\nRelative path: A shortcut from the current working directory.\n\nExample: \"data/data.csv\"\n\n\nUse getwd() to check your current working directory.\nüí° Tip: In RStudio Projects, use relative paths so your code works on any computer."
  },
  {
    "objectID": "Week2/week2_part1.html#from-data.frame-to-data.table",
    "href": "Week2/week2_part1.html#from-data.frame-to-data.table",
    "title": "Table manipulation",
    "section": "From data.frame to data.table",
    "text": "From data.frame to data.table\nRun the code chunk below. If you want, check it out using rownames().\n\n( df_letters <- data.frame( one=1:6, two=2:7, row.names=letters[1:6]) )\n\n\n\n  \n\n\n( dt_letters <- as.data.table(df_letters) )\n\n\n\n  \n\n\n\n\nHow to keep the rownames?\nSet argument keep.rownames to TRUE if you want to keep the rownames as a separate column in data.table.\n\n( dt_letters <- as.data.table(df_letters, keep.rownames=TRUE) )\n\n\n\n  \n\n\n\nInstead of keep.rownames=TRUE, you can specify the name of the column containing the rownames from the data.frame.\nExample:\n\n( dt_letters <- as.data.table(df_letters, keep.rownames=\"letters\") )\n\n\n\n  \n\n\n\n\nTask example: Convert iris to data table using as.data.table\nCreate a variable iris_dt that contains iris data set as data.table object. In this tutorial we are going to compare and analyze the default data set iris as data frame and data table objects.\n\niris_dt <- as.data.table(iris)\n\n\niris\n\n\n\n  \n\n\nrownames(iris)\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\"\n\nrownames(iris_dt)\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\" \"106\" \"107\" \"108\"\n[109] \"109\" \"110\" \"111\" \"112\" \"113\" \"114\" \"115\" \"116\" \"117\" \"118\" \"119\" \"120\"\n[121] \"121\" \"122\" \"123\" \"124\" \"125\" \"126\" \"127\" \"128\" \"129\" \"130\" \"131\" \"132\"\n[133] \"133\" \"134\" \"135\" \"136\" \"137\" \"138\" \"139\" \"140\" \"141\" \"142\" \"143\" \"144\"\n[145] \"145\" \"146\" \"147\" \"148\" \"149\" \"150\""
  },
  {
    "objectID": "Week2/week2_part1.html#row-subsetting",
    "href": "Week2/week2_part1.html#row-subsetting",
    "title": "Table manipulation",
    "section": "Row subsetting",
    "text": "Row subsetting\n\nSyntax comparison\n\n\n\n\n\n\n\n\nOperation\ndata.frame\n_data.table_\n\n\n\n\nSubseting rows\ndf[1:20, ]\ndf[1:20]\n\n\nSubseting rows based on criteria\ndf[df$id < 4, ]\ndf[id < 4]\n\n\n\n\nTask\nSelect all rows in iris_dt with Sepal.Length less than 6.7 and Petal.Length less than 1.2.\n\n# Write the solution here\n\nSelect only setosa species with more than 0.3 Petal.Width.\n\n# Write the solution here"
  },
  {
    "objectID": "Week2/week2_part1.html#column-subsetting",
    "href": "Week2/week2_part1.html#column-subsetting",
    "title": "Table manipulation",
    "section": "Column subsetting",
    "text": "Column subsetting\n\nSyntax comparison\n\n\n\n\n\n\n\n\nOperation\ndata.frame\n_data.table_\n\n\n\n\nSubseting columns\ndf[, c(1,5)]\ndf[, c(1,5)]\n\n\nSubseting columns based on colnames\ndf[, c(\"id\")]\ndf[,.(id)]\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nData.table does not use c() but .() which represents list\n\n\n\nTask\nSelect columns Petal.Length and Petal.Width and first 3 rows\n\n\n\n\n\n\nAdditional methods of subsetting columns in data.table\n\n\n\n\n\n\nTip\n\n\n\n\nUsing a character vector of column names\n\nYou can store column names in a vector and use .. to evaluate it inside data.table.\n\ncnames <- c(\"Petal.Length\", \"Petal.Width\")\n\niris_dt[1:3, ..cnames]\n\n\n\n  \n\n\n\n\nUsing a range of column names\n\nYou can select a range of columns using the : operator between two column names.\n\niris_dt[1:3, Sepal.Length:Petal.Width]\n\n\n\n  \n\n\n\n\nNegative subsetting to exclude columns\n\nUse -() or !() to exclude a range of columns.\n\niris_dt[1:3, -(Sepal.Length:Petal.Width)]\n\n\n\n  \n\n\niris_dt[1:3, !(Sepal.Length:Petal.Length)]\n\n\n\n  \n\n\n\nNote: Sepal.Length:Petal.Width works only in column context‚Äîit is not the same as numeric indexing.\n\n\n\nTask\nSelect all rows in iris_dt with Sepal.Width equal to 3.0, but show only columns for Species and Sepal.Width (Do it by using column names!). You may also try other methods of subsetting.\n\n# Write the solution here"
  },
  {
    "objectID": "Week2/week2_part1.html#operation-on-columns",
    "href": "Week2/week2_part1.html#operation-on-columns",
    "title": "Table manipulation",
    "section": "Operation on columns",
    "text": "Operation on columns\n\nSyntax comparison\n\n\n\n\n\n\n\n\nOperation\ndata.frame\ndata.table\n\n\n\n\nCalculate sum\nsum(df$id)\ndf[, sum(id)]\n\n\nCalculate sum by group\nby(df$id, df$group, sum)\ndf[, sum(id), by=group]\n\n\nCalling column out as a vector\ndf$id\ndf[, id]\n\n\n\nCalculate mean of Sepal.Width for all species.\n\niris_dt[, mean(Sepal.Width)]\n\n[1] 3.057333\n\n\nCalculate mean of Sepal.Width for and for each species\n\niris_dt[, mean(Sepal.Width), by=Species] \n\n\n\n  \n\n\n\nAlso the following syntax works for data.table because in the third part it is always the group operation when calculating something per rows: iris_dt[, mean(Sepal.Width), Species]\n\n\n\n\n\n\nAdding the column immediately when performing the operation in data.table\n\n\n\nSyntax: df[, .(new_col = sum(id) ), by=group]\nExample:\n\niris_dt[, .( mean_col = mean(Sepal.Width) ), by=Species]\n\n\n\n  \n\n\n\n\n\n\n\nThe power of data.table over data.frame\ndata.table offers an elegant and efficient way to perform multiple calculations on columns and save the results ‚Äî all in a concise syntax.\nExample: Calculate mean, standard deviation, max, min, and count of Sepal.Width by Species, then order by mean. ::: callout-important With data.table, you can chain multiple operations using square brackets [], similar in spirit to the dplyr pipe %>%. :::\n\n\n\n\n\n\n\ndata.frame\ndata.table\n\n\n\n\nmeanic <- by(iris$Sepal.Width,INDICES = iris$Species, mean) sdic <- by(iris$Sepal.Width,INDICES = iris$Species, sd) maxx <- by(iris$Sepal.Width,INDICES = iris$Species, max) minx <- by(iris$Sepal.Width,INDICES = iris$Species, min)\nres_df <- data.frame(as.numeric(meanic), as.numeric(sdic), as.numeric(maxx), as.numeric(minx))\nres_df[order(res_df$as.numeric.meanic.),]\niris_dt[ , .(mean=mean(Sepal.Width), sd=sd(Sepal.Width), min_x= min(Sepal.Width), max_x= max(Sepal.Width)), by=Species][order(mean)]\n\n\n\n\nOutput example\n\niris_dt[ , \n        .(mean=mean(Sepal.Width),\n          sd=sd(Sepal.Width),\n          min_x= min(Sepal.Width),\n          max_x= max(Sepal.Width)),\n        by=Species][order(mean)]\n\n\n\n  \n\n\n\n\nTask\nSelect all rows where Sepal.Length < 6.7 and flower species virginica and calculate mean Petal.Width in iris_dt. Do it with and without chaining.\nWith chaining\n\n# Write the solution here\n\nNo chaining\n\n# Write the solution here\n\n\n\n\nAdding new permanent columns\nAdding one columns in data table is done with := and multiple columns with ‚Äò:=‚Äô.\nHere is a new column that contains the maximal sepal width for each species was added.\n\niris_dt[, max_width1 := max(Sepal.Width), Species]\niris_dt[1:3]\n\n\n\n  \n\n\n\nAddition of multiple columns.\n\niris_dt[, \":=\" (max_width2 = max(Sepal.Width),  \n                max_width3 = max(Sepal.Length) ),\n        by=.(Species)]\niris_dt[1:3]\n\n\n\n  \n\n\n\n\nTask: Add a new column\nAdd columns to iris_dt that represent mean and sd of Petal.Width grouped by species. Columns are called meanPW and sdPW.\n\n# Write the solution here\n\nUse function uniqueN() to check how many unique mean Petal.Width there are in total and by Species group.\n\n# Write the solution here\n\n\n\n\nSpecial symbols in data.table\n.N (an integer containing the number of rows in the group)\n\niris_dt[, .N]\n\n[1] 150\n\n\nCan be used on groups. What is happening here with this subsetting in group?\n\niris_dt[, .N, by=.(Species, Sepal.Length>=4.8)]\n\n\n\n  \n\n\n\n.I (vector representing the row number)\n\niris_dt[, .(row_id=.I, Species)]\n\n\n\n  \n\n\n\nWarning! It does not assign unique row ID based on specified group!\n\niris_dt[, .(row_id=.I), by=Species][c(1,51,101)]\n\n\n\n  \n\n\n\n.GRP (an integer containing a simple group counter)\n\niris_dt[,.GRP, by=.(Species, Petal.Width>=2)]\n\n\n\n  \n\n\n\n\nExercise: :=, .N, .I, .GRP\nAdd columns to iris_dt that represent the number of observations, row number, and group ID of all rows for which Petal.Length is smaller than 6.5, grouped by Species.\n\n# Write the solution here\n\nMoreover, show only the newly added columns in your final results and use na.omit() to remove all missing values from your table\n\n# Write the solution here\n\nOne great benefit of data.table is the ability to sub-assign by reference: Try it: select all rows that have species==‚Äúvirginica‚Äù and rename those Species entries using := to new_virginica.\n\n# Write the solution here\n\n\n\nData.table special {}\nSuppressing Intermediate Output with {} is useful when you have to perform multiple consecutive calculations. Instead of adding column after a column that contains each step you can use {} to get only the final outcome and not all the intermediate steps.\n\nExample\nCreate a new variable sepal_length_diff as the difference from mean value of Sepal.Length and use function round() to round the result to one decimal\n\niris_dt[, sepal_length_diff := {\n  mean_sepal_length = mean(Sepal.Length)\n  diff_from_avg = Sepal.Length - mean_sepal_length\n  round(diff_from_avg, 1)\n}]\n\niris_dt[, .(sepal_length_diff)]\n\n\n\n  \n\n\n\n\n\nExample\nAdd two new columns to iris_dt, grouped by Species:\nsepal_length_diff ‚Äì the difference between each observation‚Äôs Sepal.Length and the group mean of Sepal.Length, rounded to one decimal.\nmean_diff ‚Äì the mean of these differences within each group (which should be approximately zero).\nUse {} inside data.table to perform intermediate calculations and return both results in one step.\n\niris_dt[, c(\"sepal_length_diff\", \"mean_diff\") := {\n  mean_sepal_length <- mean(Sepal.Length)\n  diff_from_avg <- Sepal.Length - mean_sepal_length\n  .(round(diff_from_avg, 1), mean(diff_from_avg))\n}, by = Species]\n\niris_dt[, .(sepal_length_diff, mean_diff, Species)]"
  },
  {
    "objectID": "Week2/week2_part1.html#subset-of-the-original-data.table",
    "href": "Week2/week2_part1.html#subset-of-the-original-data.table",
    "title": "Table manipulation",
    "section": "Subset of the original Data.table",
    "text": "Subset of the original Data.table\n.SD (a smaller data.table that is a Subset of the original Data.table for each group)\n.SDcols (subset columns which are then used by .SD)\n\nSelect all columns with .SD. Select only a subset of all columns by .SDcols\n\n\n\n\n\n\n\n\n\n\nSelecting columns can be done by writing column names in .SDcols (Note: It is important to write it as stings in c() )\n\niris_dt[, .SD, .SDcols=c(\"Sepal.Width\", \"Species\")][1:2]\n\n\n\n  \n\n\n\nThis allows powerful calculation on subset of desired columns and groups.\n\n\n\n\n\n\n\n\n\nYou can use lapply() together with .SD (Subset of Data) to apply functions to selected columns within groups. This is particularly useful for performing calculations like mean or sum on a subset of numeric columns.\n\niris_dt[, lapply(.SD, mean), by=Species, .SDcols=1:2]\n\n\n\n  \n\n\n\nApply mean to all numeric columns by species\n\niris_dt[, lapply(.SD, mean), by=Species, .SDcols=is.numeric]\n\n\n\n  \n\n\n\n.SD is amazing for selecting first and last row of certain group since we can imagine every group with selected table as a new separate data table. As well as other operation that can be done on data.table.\n\n\n\n\n\n\n\n\n\n\niris_dt[, .SD[c(1, .N)], by=Species]\n\n\n\n  \n\n\n\n\nTask: .SD\nOrder the results by Petal.Width and select first three (smallest) observations by species. Calculate mean of first three columns for iris_dt for those observations. Do it in one command with chaining.\n\n# Write the solution here\n\n\n\nRegular expression trick within data.table .SD\nThe combination of .SD and regular expressions provides a powerful way to work with multiple columns in data.table. Instead of typing every column name, you can use regex to select, transform, or summarize groups of variables in one step using data.table::patterns.\n\n\n\n\n\n\nNote\n\n\n\nKey points:\n- .SD contains only the columns specified in .SDcols.\n- .SDcols = patterns(\"regex1\", \"regex2\") selects columns matching all the given regex patterns.\n- Useful for grouped operations, bulk transformations, or creating multiple new columns at once.\n\n\n\nA short peek: what are regex?\n\n\n\n\n\n\nTip\n\n\n\nRegular expressions (regex) are just search patterns for text.\n- \"Sepal\" ‚Üí matches any column with \"Sepal\" in the name\n- \"^Sepal\" ‚Üí matches columns starting with \"Sepal\"\n- \"Length$\" ‚Üí matches columns ending with \"Length\"\n- \"(Sepal|Petal)\" ‚Üí matches either \"Sepal\" or \"Petal\"\n\n\nWe‚Äôll cover regex more deeply later ‚Äî for now, just think of them as ‚Äúsmart wildcards‚Äù for column names.\n\n\nExample\n\niris_dt[, lapply(.SD, mean), .SDcols = patterns(\"Sepal\")]"
  },
  {
    "objectID": "Week2/week2_part1.html#exercise-data.table",
    "href": "Week2/week2_part1.html#exercise-data.table",
    "title": "Table manipulation",
    "section": "Exercise data.table",
    "text": "Exercise data.table\nWe are going to resolve some of the task from HW1 using data.table for CO2 data.set.\n\nConvert CO2 to data.table object in a variable co2_dt.\n\n\n# Write the solution here\n\n\nCalculate the mean uptake for nonchilled plants and chilled plants.\n\n\n# Write the solution here\n\n\nAdd a new column to the dataset, smalluptake which will have values of uptake divided by 3.\n\n\n# Write the solution here\n\n\nCount the number of plants that have the value of smalluptake 3.1 or 4.1\n\n\n# Write the solution here\n\n\nAdd a column diffFromMeanUptake that will represent all the difference between uptake and the mean uptake for nonchilled plants and chilled plants.\n\n\n# Write the solution here"
  },
  {
    "objectID": "Week3/week3_part1.html",
    "href": "Week3/week3_part1.html",
    "title": "Data visualization with ggplot2",
    "section": "",
    "text": "Tidy data makes the analysis easier to do, faster to check, easier to plot and to reuse for other analysis. If you have a messy dataset and you think that it is exactly what you need, you will most likely use it only once - for one analysis and a single graph.\n\n1. Each variable forms a column.\n\n2. Each observation forms a row.\n\n3. Each type of observational unit forms a table.\n\n\n\n\n\nFig1. Rules that make data tidy\n\n\n\n\n\n\nExamples of messy and tidy datasets (based on a dataset of TB cases in different countries).\n\n\n\n\n\n\n  \n    \n      country\n      cases_1999\n      cases_2000\n      population_1999\n      population_2000\n    \n  \n  \n    Afghanistan\n745\n2666\n19987071\n20595360\n    Brazil\n37737\n80488\n172006362\n174504898\n    China\n212258\n213766\n1272915272\n1280428583\n  \n  \n  \n\n\nFig2. Messy data\n\n\n\n\n\n\n\n\n  \n    \n      country\n      year\n      cases\n      population\n    \n  \n  \n    Afghanistan\n1999\n745\n19987071\n    Afghanistan\n2000\n2666\n20595360\n    Brazil\n1999\n37737\n172006362\n    Brazil\n2000\n80488\n174504898\n    China\n1999\n212258\n1272915272\n    China\n2000\n213766\n1280428583\n  \n  \n  \n\n\nFig3. Tidy data\n\n\nAdvantages of using tidy data:\n\nConsistent data structure makes it easier to learn the tools that work with it because they have an underlying uniformity.\nPlacing variables in columns makes use of R‚Äôs vectorization (functions and operations automatically apply element-wise to entire vectors).\nFor more information see Chapter 5: Data tidying from\nGrolemund, G., √áetinkaya-Rundel, M., & Wickham, H. (2023). R for Data Science (2nd ed.). O‚ÄôReilly Media.\n\n\n\n\n\nCoherent system of packages for data manipulation, exploration and visualization that share a common design philosophy\nMostly developed by Hadley Wickham\nhttps://www.tidyverse.org/\n\n\n\n\n\n\nFig3. Tidyverse\n\n\n\n\nMore information: What is the tidyverse\n\n\n\nThis dataset represents simulated qPCR (quantitative PCR) results used to measure gene expression differences between a control group and a treatment group over a 24-hour time point. Each sample has Ct (cycle threshold) values for both a target gene (the gene of interest) and a reference gene (a housekeeping gene used for normalization), measured across two technical replicates. The raw data are intentionally messy and wide-formatted, resembling typical qPCR output files that contain mixed data types, missing values, inconsistent naming, and combined experimental variables (e.g., ‚ÄúTreatment_24h‚Äù).\nOur goal is to clean and restructure this data into a tidy format where each observation corresponds to a single sample-replicate pair, with separate columns for condition, time, and gene measurements.\nFirst we will simulate some data:\n\nset.seed(42)\n\n# ---- 1. Simulate MESSY qPCR data (wide format) ----\n\nmessy_qpcr <- data.table(\n  Sample = c(\"ctrl_1\", \"ctrl_2\", \"ctrl3\", \"treat1\", \"treat_2\", \"treat_3\"),\n  Target_CT_Rep1 = c(22.1, 23.0, \"22_low\", 18.5, 19.3, 18.9),\n  Target_CT_Rep2 = c(22.3, \"missing\", 21.9, 18.4, 19.5, 19.0),\n  Ref_CT_Rep1 = c(20.0, \"20.2\", \"19.8\", 18.0, 17.7, \"err\"),\n  Ref_CT_Rep2 = c(\"19.9\", 20.1, 19.9, 18.1, \"error\", 17.8),\n  Condition_Time = c(\"Control_24h\", \"Control_24h\", \"Control_24h\", \"Treatment_24\", \"Treatment_24h\", \"Treatment_24h\")\n)\n\ngt(messy_qpcr, caption=\"Messy wide-format data\")\n\n\n\n\n\n  Messy wide-format data\n  \n    \n      Sample\n      Target_CT_Rep1\n      Target_CT_Rep2\n      Ref_CT_Rep1\n      Ref_CT_Rep2\n      Condition_Time\n    \n  \n  \n    ctrl_1\n22.1\n22.3\n20\n19.9\nControl_24h\n    ctrl_2\n23\nmissing\n20.2\n20.1\nControl_24h\n    ctrl3\n22_low\n21.9\n19.8\n19.9\nControl_24h\n    treat1\n18.5\n18.4\n18\n18.1\nTreatment_24\n    treat_2\n19.3\n19.5\n17.7\nerror\nTreatment_24h\n    treat_3\n18.9\n19\nerr\n17.8\nTreatment_24h\n  \n  \n  \n\n\n\n\nQ1: What is messy about this data?\nWe now have to tidy the data so that each row corresponds to one observation. We will use data.table for this.\n\n# ---- 2. Clean the data ----\n# Convert non-numeric Ct values\n# get the vector of column names with CT\nnot_numeric_CT <- names(messy_qpcr[,.SD,.SDcols=patterns(\"CT\")])\n# clean the values in those columns\nmessy_qpcr[, (not_numeric_CT) := lapply(.SD, function(x) {\n  x <- gsub(\"_low\", \"\", x)                    # remove \"_low\"\n  x[x %in% c(\"missing\", \"error\", \"err\")] <- NA  # replace text errors with NA\n  as.numeric(x)                               # convert to numeric\n}),\n  .SDcols = not_numeric_CT\n]\n\n# Fix inconsistent naming in condition\nmessy_qpcr[, Condition_Time := gsub(\"Treatment_24$\", \"Treatment_24h\", Condition_Time)]\n\n# ---- 3. Transform to tidy format ----\n# Melt replicates to long form\ntidy_qpcr <- melt(\n  messy_qpcr,\n  id.vars = c(\"Sample\", \"Condition_Time\"),\n  measure.vars = patterns(Target = \"^Target_CT_\", Reference = \"^Ref_CT_\"),\n  variable.name = \"Replicate\"\n)\n\n# Split condition and time\ntidy_qpcr[, c(\"Condition\", \"Time\") := tstrsplit(Condition_Time, \"_\", fixed = TRUE)]\n\ngt(tidy_qpcr, caption = \"Tidy qPCR data\")\n\n\n\n\n\n  Tidy qPCR data\n  \n    \n      Sample\n      Condition_Time\n      Replicate\n      Target\n      Reference\n      Condition\n      Time\n    \n  \n  \n    ctrl_1\nControl_24h\n1\n22.1\n20.0\nControl\n24h\n    ctrl_2\nControl_24h\n1\n23.0\n20.2\nControl\n24h\n    ctrl3\nControl_24h\n1\n22.0\n19.8\nControl\n24h\n    treat1\nTreatment_24h\n1\n18.5\n18.0\nTreatment\n24h\n    treat_2\nTreatment_24h\n1\n19.3\n17.7\nTreatment\n24h\n    treat_3\nTreatment_24h\n1\n18.9\nNA\nTreatment\n24h\n    ctrl_1\nControl_24h\n2\n22.3\n19.9\nControl\n24h\n    ctrl_2\nControl_24h\n2\nNA\n20.1\nControl\n24h\n    ctrl3\nControl_24h\n2\n21.9\n19.9\nControl\n24h\n    treat1\nTreatment_24h\n2\n18.4\n18.1\nTreatment\n24h\n    treat_2\nTreatment_24h\n2\n19.5\nNA\nTreatment\n24h\n    treat_3\nTreatment_24h\n2\n19.0\n17.8\nTreatment\n24h\n  \n  \n  \n\n\n\n\n\n\n\nWe can write the tidied dataset to a file using various functions (write.table(), write.csv(), write.tsv()). However, the variable type information for different columns will be lost if we read the data back in from the file.\nThis is why we can directly save the objects that we created using save() or saveRDS().\nsave()\n\nSaves one or more R objects to a binary .RData file.\nLoads all saved objects with original names using load().\n\nsaveRDS()\n\nSaves a single R object to a .rds file.\nAllows loading with a new name using readRDS().\nMore flexible for saving/loading single objects.\n\n\n# Save the tidy_qpcr object to a RDS file\nsaveRDS(tidy_qpcr, \"tidied.qpcr.data.rds\")\n\n# Use list.files() function to check whether the file got created\nlist.files(pattern = \"rds\")\n\n[1] \"tidied.qpcr.data.rds\"\n\n# Load the object under a different name\ntidy_new = readRDS(\"tidied.qpcr.data.rds\")\n\n# Check if the metadata is preserved\nstr(tidy_qpcr)\n\nClasses 'data.table' and 'data.frame':  12 obs. of  7 variables:\n $ Sample        : chr  \"ctrl_1\" \"ctrl_2\" \"ctrl3\" \"treat1\" ...\n $ Condition_Time: chr  \"Control_24h\" \"Control_24h\" \"Control_24h\" \"Treatment_24h\" ...\n $ Replicate     : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 2 2 2 2 ...\n $ Target        : num  22.1 23 22 18.5 19.3 18.9 22.3 NA 21.9 18.4 ...\n $ Reference     : num  20 20.2 19.8 18 17.7 NA 19.9 20.1 19.9 18.1 ...\n $ Condition     : chr  \"Control\" \"Control\" \"Control\" \"Treatment\" ...\n $ Time          : chr  \"24h\" \"24h\" \"24h\" \"24h\" ...\n - attr(*, \".internal.selfref\")=<externalptr> \n\nstr(tidy_new)\n\nClasses 'data.table' and 'data.frame':  12 obs. of  7 variables:\n $ Sample        : chr  \"ctrl_1\" \"ctrl_2\" \"ctrl3\" \"treat1\" ...\n $ Condition_Time: chr  \"Control_24h\" \"Control_24h\" \"Control_24h\" \"Treatment_24h\" ...\n $ Replicate     : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 2 2 2 2 ...\n $ Target        : num  22.1 23 22 18.5 19.3 18.9 22.3 NA 21.9 18.4 ...\n $ Reference     : num  20 20.2 19.8 18 17.7 NA 19.9 20.1 19.9 18.1 ...\n $ Condition     : chr  \"Control\" \"Control\" \"Control\" \"Treatment\" ...\n $ Time          : chr  \"24h\" \"24h\" \"24h\" \"24h\" ...\n - attr(*, \".internal.selfref\")=<externalptr> \n\n\nWe can use save() to save individual objects or the entire environment.\n\n# Saves all objects\nsave(list = ls(), file = \"my_workspace.RData\")\n# Saves all objects\nsave(list = ls(), file = \"my_workspace2.RData\")\n\nlist.files(pattern = \"RData\")\n\n[1] \"my_workspace.RData\"  \"my_workspace2.RData\"\n\n\n\n\n\nSince out data is now tidy, we now want to calculate normalized gene expression levels for relative quantification of gene expression from qPCR (quantitative PCR) data. We will use the \\(\\Delta\\Delta\\)Ct method.\n\n\n\n\n\nFig5. delta_delta_Ct method\n\n\n\n\nTo calculate \\(\\Delta\\Delta\\)Ct we need to perform the folowing steps:\n\n\n\n\n\nFig6. delta_delta_Ct calculation\n\n\n\n\nWe will now perform the necessary steps on our tidied qPCR dataset.\n\n# ---- 4. Calculate ŒîCt ----\ntidy_qpcr[, delta_Ct := Target - Reference]\n\n# ---- 5. Calculate ŒîŒîCt ----\nmean_control_deltaCt <- tidy_qpcr[Condition == \"Control\", mean(delta_Ct, na.rm = TRUE)]\ntidy_qpcr[, delta_delta_Ct := delta_Ct - mean_control_deltaCt]\n\n# ---- 6. Calculate relative expression ----\ntidy_qpcr[, rel_expression := 2^(-delta_delta_Ct)]\n\n# ---- 7. Summarize per condition ----\nsummary_qpcr <- tidy_qpcr[, .( mean_deltaCt = mean(delta_Ct, na.rm =\nTRUE), mean_rel_expression = mean(rel_expression, na.rm = TRUE) ), by =\nCondition]\n\n\ngt(tidy_qpcr, caption = \"ŒîŒîCt and relative expression results\")\n\n\n\n\n\n  ŒîŒîCt and relative expression results\n  \n    \n      Sample\n      Condition_Time\n      Replicate\n      Target\n      Reference\n      Condition\n      Time\n      delta_Ct\n      delta_delta_Ct\n      rel_expression\n    \n  \n  \n    ctrl_1\nControl_24h\n1\n22.1\n20.0\nControl\n24h\n2.1\n-0.2\n1.1486984\n    ctrl_2\nControl_24h\n1\n23.0\n20.2\nControl\n24h\n2.8\n0.5\n0.7071068\n    ctrl3\nControl_24h\n1\n22.0\n19.8\nControl\n24h\n2.2\n-0.1\n1.0717735\n    treat1\nTreatment_24h\n1\n18.5\n18.0\nTreatment\n24h\n0.5\n-1.8\n3.4822023\n    treat_2\nTreatment_24h\n1\n19.3\n17.7\nTreatment\n24h\n1.6\n-0.7\n1.6245048\n    treat_3\nTreatment_24h\n1\n18.9\nNA\nTreatment\n24h\nNA\nNA\nNA\n    ctrl_1\nControl_24h\n2\n22.3\n19.9\nControl\n24h\n2.4\n0.1\n0.9330330\n    ctrl_2\nControl_24h\n2\nNA\n20.1\nControl\n24h\nNA\nNA\nNA\n    ctrl3\nControl_24h\n2\n21.9\n19.9\nControl\n24h\n2.0\n-0.3\n1.2311444\n    treat1\nTreatment_24h\n2\n18.4\n18.1\nTreatment\n24h\n0.3\n-2.0\n4.0000000\n    treat_2\nTreatment_24h\n2\n19.5\nNA\nTreatment\n24h\nNA\nNA\nNA\n    treat_3\nTreatment_24h\n2\n19.0\n17.8\nTreatment\n24h\n1.2\n-1.1\n2.1435469\n  \n  \n  \n\n\n\ngt(summary_qpcr, caption = \"Summary results\")\n\n\n\n\n\n  Summary results\n  \n    \n      Condition\n      mean_deltaCt\n      mean_rel_expression\n    \n  \n  \n    Control\n2.3\n1.018351\n    Treatment\n0.9\n2.812563\n  \n  \n  \n\n\n\n\nYou can check out this tutorial on qPCR analysis for more details."
  },
  {
    "objectID": "Week3/week3_part1.html#types-of-graphs-in-r",
    "href": "Week3/week3_part1.html#types-of-graphs-in-r",
    "title": "Data visualization with ggplot2",
    "section": "Types of graphs in R",
    "text": "Types of graphs in R\n\nGraphs in R\nVariable types:\n\ncategorical :\n  nominal  \n  ordinal    \nquantitative :\n  numerical discrete  \n  numerical continuous  \n\nAppropriate graphs depend on the number and type of variables that we are plotting.\n\n\n\n\n\nFig7. Graphs by variable type\n\n\n\n\nLet‚Äôs again simulate some data which we will use for different types of visualizations.\n\nset.seed(123)\n\n# Simulate dataset\n\nn_samples <- 40\n\ndf <- data.table(\n  SampleID = paste0(\"S\", 1:n_samples),\n  Treatment = rep(c(\"Control\", \"Treated\"), each = n_samples/2),\n  CellType = sample(c(\"TypeA\", \"TypeB\"), n_samples, replace = TRUE),\n  Mutation = sample(c(\"WT\", \"Mut\"), n_samples, replace = TRUE),\n  NumMutations = sample(0:5, n_samples, replace = TRUE),\n  Gene1_expr = rnorm(n_samples, mean = ifelse(rep(c(\"Control\", \"Treated\"), each = n_samples/2) == \"Control\", 10, 12), sd = 2),\n  Gene2_expr = rnorm(n_samples, mean = ifelse(rep(c(\"Control\", \"Treated\"), each = n_samples/2) == \"Control\", 8, 9), sd = 1.5),\n  Protein_expr = rnorm(n_samples, mean = ifelse(rep(c(\"Control\", \"Treated\"), each = n_samples/2) == \"Control\", 50, 60), sd = 8)\n)\n\ngt(head(df, n= 10), caption = \"Dataset for visualizations\")\n\n\n\n\n\n  Dataset for visualizations\n  \n    \n      SampleID\n      Treatment\n      CellType\n      Mutation\n      NumMutations\n      Gene1_expr\n      Gene2_expr\n      Protein_expr\n    \n  \n  \n    S1\nControl\nTypeA\nWT\n5\n11.844535\n7.429660\n66.80087\n    S2\nControl\nTypeA\nMut\n5\n14.100169\n9.378495\n39.70376\n    S3\nControl\nTypeA\nMut\n2\n9.017938\n7.136980\n56.30191\n    S4\nControl\nTypeB\nWT\n5\n5.381662\n8.911946\n56.15234\n    S5\nControl\nTypeA\nWT\n5\n12.011477\n5.573176\n52.65762\n    S6\nControl\nTypeB\nWT\n0\n8.581598\n7.916657\n41.93299\n    S7\nControl\nTypeB\nWT\n5\n8.623983\n8.779111\n49.04438\n    S8\nControl\nTypeB\nMut\n1\n12.051143\n8.451730\n47.75684\n    S9\nControl\nTypeA\nWT\n0\n9.430454\n8.158514\n54.50392\n    S10\nControl\nTypeA\nWT\n1\n7.558565\n7.038941\n47.02049\n  \n  \n  \n\n\n\n\nCategorical variables example:\n\n\n\n\n\nQuantitative variables examples:\nNumerical continuous:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical discrete:\n\n\n\n\n\n\n\nGraphs with two variables: Continuous X, Continuous Y\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphs with two variables: Discrete X, Continuous Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphs with two variables: Discrete X, Discrete Y\n\n\n\n\n\n\n\n\n\n\n\nQ2: Let‚Äôs simulate another tidy qPCR dataset. What would be the appropriate graphs for the following research questions:\n\nset.seed(123)\n\ngenes <- c(\"TP53\", \"MYC\", \"GAPDH\", \"BRCA1\")\nn_samples <- 8\n\n# Create samples data.table\nsamples <- data.table(\n  SampleID = paste0(\"S\", 1:n_samples),\n  Condition = rep(c(\"Control\", \"Treated\"), each = n_samples/2)\n)\n\n# Create qpcr_raw by expanding genes and SampleID, joining sample info, and simulating Ct values\nqpcr_raw <- CJ(Gene = genes, SampleID = samples$SampleID)[\n  samples, on = \"SampleID\"\n][\n  , Ct := fifelse(Gene == \"TP53\" & Condition == \"Control\", rnorm(.N, 22, 1),\n           fifelse(Gene == \"TP53\" & Condition == \"Treated\", rnorm(.N, 20, 1),\n           fifelse(Gene == \"MYC\" & Condition == \"Control\", rnorm(.N, 18, 1),\n           fifelse(Gene == \"MYC\" & Condition == \"Treated\", rnorm(.N, 17, 1),\n           fifelse(Gene == \"BRCA1\" & Condition == \"Control\", rnorm(.N, 24, 1),\n           fifelse(Gene == \"BRCA1\" & Condition == \"Treated\", rnorm(.N, 22, 1),\n           rnorm(.N, 15, 0.5)))))))]\n\n# Compute deltaCt normalized to GAPDH Ct per SampleID\nqpcr_dCt <- merge(\n  qpcr_raw,\n  qpcr_raw[Gene == \"GAPDH\", .(SampleID, Ct_ref = Ct)],\n  by = \"SampleID\"\n)[\n  , deltaCt := Ct - Ct_ref\n]\n\n# Compute deltaDeltaCt and fold change by gene\nqpcr_ddCt <- qpcr_dCt[\n  , .(mean_dCt_control = mean(deltaCt[Condition == \"Control\"])), by = Gene\n][\n  qpcr_dCt, on = \"Gene\"\n][\n  , deltaDeltaCt := deltaCt - mean_dCt_control\n][\n  , fold_change := 2^(-deltaDeltaCt)\n][\n  Gene != \"GAPDH\"  # filter out reference gene\n]\n\n\n\ngt(qpcr_ddCt, caption = \"Tidied qPCR data, example 2\")\n\n\n\n\n\n  Tidied qPCR data, example 2\n  \n    \n      Gene\n      mean_dCt_control\n      SampleID\n      Condition\n      Ct\n      Ct_ref\n      deltaCt\n      deltaDeltaCt\n      fold_change\n    \n  \n  \n    BRCA1\n8.743939\nS1\nControl\n23.03814\n14.55232\n8.485825\n-0.2581137\n1.1959140\n    MYC\n3.026427\nS1\nControl\n18.44821\n14.55232\n3.895891\n0.8694645\n0.5473500\n    TP53\n7.401852\nS1\nControl\n22.07051\n14.55232\n7.518190\n0.1163380\n0.9225264\n    BRCA1\n8.743939\nS2\nControl\n24.04123\n14.37436\n9.666869\n0.9229299\n0.5274368\n    MYC\n3.026427\nS2\nControl\n17.50897\n14.37436\n3.134605\n0.1081776\n0.9277593\n    TP53\n7.401852\nS2\nControl\n20.73494\n14.37436\n6.360574\n-1.0412777\n2.0580495\n    BRCA1\n8.743939\nS3\nControl\n22.53936\n15.65621\n6.883153\n-1.8607853\n3.6320531\n    MYC\n3.026427\nS3\nControl\n17.31199\n15.65621\n1.655785\n-1.3706421\n2.5858562\n    TP53\n7.401852\nS3\nControl\n22.35981\n15.65621\n6.703607\n-0.6982448\n1.6225296\n    BRCA1\n8.743939\nS4\nControl\n24.70178\n14.76188\n9.939908\n1.1959691\n0.4364932\n    MYC\n3.026427\nS4\nControl\n18.18130\n14.76188\n3.419427\n0.3930000\n0.7615444\n    TP53\n7.401852\nS4\nControl\n23.78691\n14.76188\n9.025037\n1.6231845\n0.3246181\n    BRCA1\n8.743939\nS5\nTreated\n22.03779\n14.97299\n7.064802\n-1.6791363\n3.2023617\n    MYC\n3.026427\nS5\nTreated\n17.51941\n14.97299\n2.546421\n-0.4800057\n1.3947492\n    TP53\n7.401852\nS5\nTreated\n19.97145\n14.97299\n4.998467\n-2.4033848\n5.2904293\n    BRCA1\n8.743939\nS6\nTreated\n20.93667\n14.74197\n6.194706\n-2.5492329\n5.8532299\n    MYC\n3.026427\nS6\nTreated\n16.15030\n14.74197\n1.408328\n-1.6180994\n3.0697036\n    TP53\n7.401852\nS6\nTreated\n21.51647\n14.74197\n6.774503\n-0.6273496\n1.5447245\n    BRCA1\n8.743939\nS7\nTreated\n21.76372\n14.63847\n7.125253\n-1.6186853\n3.0709506\n    MYC\n3.026427\nS7\nTreated\n16.50944\n14.63847\n1.870976\n-1.1554514\n2.2275401\n    TP53\n7.401852\nS7\nTreated\n20.21594\n14.63847\n5.577475\n-1.8243776\n3.5415418\n    BRCA1\n8.743939\nS8\nTreated\n22.75405\n15.30899\n7.445061\n-1.2988778\n2.4603744\n    MYC\n3.026427\nS8\nTreated\n17.23539\n15.30899\n1.926394\n-1.1000333\n2.1435964\n    TP53\n7.401852\nS8\nTreated\n18.98142\n15.30899\n3.672432\n-3.7294204\n13.2637830\n  \n  \n  \n\n\n\n\n\nComparison of TP53 and MYC expression\nComparison of ŒîCt values across control and treated samples\nAverage protein levels per treatment group\nValue of deltaDeltaCt by sample and gene\n\n\n\nggplot2 vs.¬†base R plots\nplot() - generic function in base R (type of plot depends on the type/class of the first argument)\n\n\n\n\n\n\n\n\n\n\nCheck out ggplot cheat sheet to see which type of plot fits your kind of data."
  },
  {
    "objectID": "Week3/week3_part1.html#basics-of-ggplot2",
    "href": "Week3/week3_part1.html#basics-of-ggplot2",
    "title": "Data visualization with ggplot2",
    "section": "Basics of ggplot2",
    "text": "Basics of ggplot2\n\nBasic ggplot logic: ggplot(data, aes(x,y))\nThe ggplot() object acts as a storage facility for the data. It is here where we define the data frame that houses the x and y coordinate values themselves and instructions on how to split the data. There are three ways to initialise a ggplot() object:\np <- ggplot()\np <- ggplot(data_frame)\np <- ggplot(data_frame, aes(x, y))\nDisplaying the object p generated in the code chunk above would result in Error: No layers in plot. This is because you always need at least one layer for a ggplot.\n\n\nMapping aesthetics to data\nThe aes() aesthetic mapping function lives inside a ggplot object and is where we specify the set of plot attributes (x and y axis, color) that remain constant throughout the subsequent layers (unless overwritten, more on this later).\nWe can consider the relationship between the aes() and geoms components as follows:\nThe aes() function is how data is stored, how data is split, and geoms is what the data looks like. These are geometrical objects stored in subsequent layers.\n\n\nLayers\nWe use the + operator to construct. By appending layers we can connect the ‚Äúhow‚Äù (aesthetics) to the ‚Äúwhat‚Äù (geometric objects). Adding geometric, scale, facet and statistic layers to a ggplot() object is how to control virtually every visual aspect of the plot from the data contained in the object.\n\n\nAdding a geometric object layer\nA geometric object is used to define the style of the plot. Common geometric objects include:\ngeom_point() which is used to draw a dot plot\ngeom_line() used to draw a line plot\ngeom_bar() used to draw a bar chart.\nAvailable graphs can be seen at R graph gallery\n\n\nFacets\nAppending a facet layer to a ggplot generates the same plot for different subsets of data.\n\n\nStatistics\nExploratory data analysis can be done using the base packages in R, the results of which can be added to a ggplot() in the guise of a geom layer.\n\n\nData for examples\nIn this lecture we will be using microarray expression data for 2 microarray probes measured in leukemia patients with different cancer stages. The data is available at http://hex.bioinfo.hr/~rosa/R_workshop/1242_at.leukemia.txt and http://hex.bioinfo.hr/~rosa/R_workshop/1866_g_at.leukemia.txt\n\n# read in the data for the 1242_at probe expression levels\n\ndata <- read.delim(\"http://hex.bioinfo.hr/~rosa/R_workshop/1242_at.leukemia.txt\");data\n\n\n\n  \n\n\n\n\n\nExample: basic layout\n\nx axis is categorical, y axis is numerical\n\nSet the basic layout:\n\nWe want to analyze the 1242_at probe and visualize the differences of expression across stages. Produce a layout in which the x axis represents the stage and the y axis represents expression of the 1242_at probe.\n\n\n# read in the data for the 1242_at probe expression levels\n\ndata <- read.delim(\"http://hex.bioinfo.hr/~rosa/R_workshop/1242_at.leukemia.txt\")\n\nHint: You need to tell ggplot what your data is and define the aesthetics.\n\n# create a layout in which x axis to represent stage and y to represent expression\n\np <- ggplot(data, aes(x = stage, y = expression))\np\n\n\n\n\n\n\nExample: add a layer - graph type\nChoose the graph type that you want to show. Lets say we want a scatterplot of 1242_at expression values for each stage. Add geom_point() to your layout.\nHint: We need to define data and aesthetics and add layers to the existing plot using ‚Äú+‚Äù.\n\n# add points to your plot\n\np <- ggplot(data, aes(x = stage, y = expression)) + geom_point()\np\n\n\n\n\n\n\n\n\n\nExample: modifying the graph with aesthetics\nAesthetics can be defined inside the ggplot() call or inside individual layers. Color the points by stage. Do this inside geom_point.\n\n# color the points by stage\n\n\np <- ggplot(data, aes(x = stage, y = expression)) + geom_point(aes(color = stage))\np\n\n\n\n\n\n\nExample: add another layer (boxplot)\nWe wanted a scatterplot but changed out mind and now we also want boxplot on top of this scatterplot. Add + geom_boxplot() to the previous line to see what you get.\nHint: Layers are added using ‚Äú+‚Äù.\n\n# add a boxplot layer\n\np <- ggplot(data, aes(x = stage, y = expression)) + geom_point(aes(color = stage)) + geom_boxplot()\np\n\n\n\n\nThere are also color palettes such as viridis palette designed to be perceived by viewers with common forms of color blindness.\n\np <- ggplot(iris, aes(x=Species, y=Sepal.Length, fill= Species)) +\n  geom_boxplot() + \n  scale_fill_viridis_d()+\n  theme_light()\np\n\n\n\n\n\n\nExample: Setting aesthetics\nThe aes() function in ggplot2 maps data variables to visual properties (aesthetics) and can be specified: - inside ggplot() to apply globally - inside individual layers to apply locally - set outside aes() to apply a constant value rather than a mapped variable\n\n# 1. Aesthetics mapped inside aes(): color mapped to Species (varies by data)\np1 <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  ggtitle(\"Color mapped inside aes()\")\np1\n\n\n\n# 2. Aesthetics set outside aes(): color fixed to blue for all points \np2 <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(color = \"blue\") +\n  ggtitle(\"Color set outside aes()\")\np2\n\n\n\n# 3. Aesthetics mapped inside aes() globally, and overridden or added in layer's aes():\np3 <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(aes(color = Species)) +   # color mapped per Species, local layer aes()\n  geom_smooth(method = \"lm\", color = \"black\") +  # smooth line fixed black color, outside aes()\n  ggtitle(\"Color aes() in point layer, fixed color outside aes() in smooth\")\np3\n\n\n\n\n\n\nExample: Identify parts of the plot are produced by which part of command\n\nset.seed(123)\nmolecular_data <- data.frame(\n  TP53 = rnorm(50, mean = 10, sd = 3),\n  BRCA1 = rnorm(50, mean = 8, sd = 2),\n  DiseaseStatus = rep(c(\"Healthy\", \"Tumor\"), each = 25)\n)\n\np2 <- ggplot(molecular_data, aes(x = TP53, y = BRCA1, color = DiseaseStatus)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Gene expression: TP53 vs BRCA1 by disease status\",\n       x = \"TP53 expression (log2 counts)\",\n       y = \"BRCA1 expression (log2 counts)\")\n\np2\n\n\n\n\nFor each plot element below, identify which part of the ggplot2 command produced it:\n\nThe scatter plot points colored by disease status\nThe red smoothing line (linear regression)\nThe main plot title\nThe x-axis label\nThe y-axis label\nThe specification of which genes are on the x and y axes\nThe plot panel background and gridlines"
  },
  {
    "objectID": "Week3/week3_part1.html#facets-1",
    "href": "Week3/week3_part1.html#facets-1",
    "title": "Data visualization with ggplot2",
    "section": "Facets",
    "text": "Facets\n\nExample 3: Let‚Äôs build another graph\nWe want to see if there is any connection between expression of probe 1242_at and probe 1866_g_at in the leukemia dataset. We will create a graph with numerical x (1242_at expression) and y (1866_g_at expression) axes.\nFirst let‚Äôs read in and combine the datasets.\n\n# Read data with fread for efficiency\ndata1 <- fread(\"http://hex.bioinfo.hr/~rosa/R_workshop/1242_at.leukemia.txt\")\ndata2 <- fread(\"http://hex.bioinfo.hr/~rosa/R_workshop/1866_g_at.leukemia.txt\")\n\n# Rename the 'expression' columns by reference\nsetnames(data1, \"expression\", \"expression_1242_at\")\nsetnames(data2, \"expression\", \"expression_1866_g_at\")\n\n# Perform an inner join on 'row.names' and 'stage' columns\ndata <- merge(data1, data2, by = c(\"V1\", \"stage\"), all = FALSE)\n\n# View the result\nhead(data)\n\n\n\n  \n\n\n\nNow we want to make a scatterplot and see whether there is any connection between expression_1242_at (x axis) and expression_1866_g_at (y axis) in leukemia dataset.\nHint: You need to make a basic layer, define aesthetics and add a layer with the points.\n\n# make a scatterplot with expression_1242_at on the x axis and expression_1866_g_at on the y axis\n\np <- ggplot(data, aes(x = expression_1242_at, y = expression_1866_g_at)) + geom_point() \np\n\n\n\n\n\n\n\nThis looks ok but now we would like for each stage to appear in its own graph. For this use facet_wrap(). Parameter to facet_wrap is the variable by which you would want to separate the graphs (~variable2). If you put ~variable2, then the graph will be separated into as many columns as there are levels in variable2. Lets separate our scatterplot to columns by ‚Äústage‚Äù variable.\nHint: You need to add a facet to the previous plot.\n\n# make a scatterplot with expression_1242_at on the x axis and expression_1866_g_at on the y axis\n\np <- ggplot(data, aes(x = expression_1242_at, y = expression_1866_g_at)) + geom_point() +facet_wrap(~stage)\np"
  },
  {
    "objectID": "Week3/week3_part1.html#statistics-1",
    "href": "Week3/week3_part1.html#statistics-1",
    "title": "Data visualization with ggplot2",
    "section": "Statistics",
    "text": "Statistics\nLet‚Äôs do some exploratory analysis and add linear regression lines to the plot, to check whether the relationship between the expression values of the two probes is similar in all stages. We can check this by adding geom_smooth() to the plot.\n\n# add linear regression lines to the plot with the facets\n\n\np <- ggplot(data, aes(x = expression_1242_at, y = expression_1866_g_at)) + geom_point() +facet_wrap(~stage) + geom_smooth(method = \"lm\")\np\n\n\n\n\nHint: You can check the available smoothing methods with ?geom_smooth.\nWe can also show medians and ranges in various ways:\n\ny <- c(18, 11, 16)\ndf <- data.frame(x = 1:3, y = y, se = c(1.2, 0.5, 1.0))\n\nbase <- ggplot(df, aes(x, y, ymin = y - se, ymax = y + se))\n\n\nbase + geom_crossbar()\n\n\n\n\n\nbase + geom_pointrange()\n\n\n\n\n\nbase + geom_errorbar()\n\n\n\n\nThere are several R packages for adding statistical annotations to plots (particularly with ggplot2):\nggpubr: Adds correlation coefficients, p-values, and other statistics with functions like stat_cor() easily on ggplot2 plots. ggpubr\nggpval: Automatically performs statistical tests (t-tests, Wilcoxon, etc.) between groups and annotates p-values on ggplot2 plots. ggpval\nggstatsplot: Creates visually informative plots with statistical details, significance tests, and effect sizes included by default. ggstatsplot\nggsignif: Provides an easy way to add significance brackets to ggplot2 plot. ggsignif\nLets add a correlation coefficient to the scatterplot with expression_1242_at on the x axis and expression_1866_g_at on the y axis (with facets by stage).\n\nlibrary(ggpubr)\np <- ggplot(data, aes(x = expression_1242_at, y = expression_1866_g_at)) + \n  geom_point() +\n  facet_wrap(~stage) +\n  stat_cor(method = \"pearson\")\np"
  },
  {
    "objectID": "Week3/week3_part1.html#themes",
    "href": "Week3/week3_part1.html#themes",
    "title": "Data visualization with ggplot2",
    "section": "Themes",
    "text": "Themes\nMany visual aspects of the plots can be adjusted using theme() and scale_X_Y() There are various themes already available, but they can also be tweaked\nggpubr package let‚Äôs you produce publication-ready plots, with various themes, adding statistics to plots and combining various ggplot objects into one figure. https://rpkgs.datanovia.com/ggpubr/\nggsci package includes scientific journal and Sci-Fi themed color palettes for ggplot2 https://cran.r-project.org/web/packages/ggsci/vignettes/ggsci.html\nWe can make our scatterplot a bit nicer.\n\np <- ggplot(data, aes(x = expression_1242_at, y = expression_1866_g_at)) + \n  geom_point() +\n  facet_wrap(~stage) +\n  stat_cor(method = \"pearson\")+\n  theme_classic2()\np\n\n\n\n\nWe can save our plots using the ggsave() function. The function saves a single ggplot object to a file (PNG, PDF, SVG, TIFF, etc.) with customizable size, resolution, and format based on the filename extension.\n\nggsave(\"my.first.plot.png\", plot = p, width = 12, height = 7)\n\nOnce you find the best way to visualize the data, you can simply change the dataset of the ggplot object using the ggplot %+% operator\n\np <- ggplot(mtcars, aes(mpg, wt, color=factor(cyl))) + \n  geom_point(shape=20, size=4)\nprint(p)\n\n\n\np2<-p %+% mtcars[mtcars$disp>200,]\nprint(p2)\n\n\n\n\nFor more information and help with making graphs see the R Graphics Cookbook\n\nExercise\nFor the qpcr_ddCt data set produce plots that visualize: 1. Comparison of TP53 and MYC expression 2. Comparison of ŒîCt values across control and treated samples"
  },
  {
    "objectID": "Week3/week3_part2.html",
    "href": "Week3/week3_part2.html",
    "title": "Regular expressions",
    "section": "",
    "text": "# load packages tidyverse, data.table\n\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(gt)\nlibrary(hexbin)"
  },
  {
    "objectID": "Week3/week3_part2.html#regular-expressions",
    "href": "Week3/week3_part2.html#regular-expressions",
    "title": "Regular expressions",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n \n\n\n\n\n\n\n\nWhat are Regular Expressions?\nRegex are minimal strings that represent a pattern.  Such strings contain special characters that can represent:\n\nBoolean Operations\nGrouping\nQuantification\nWildcards\n\n\n\nSome History\nRegex were born in theoretical computer science during the early 50s as part of the description of ‚ÄòRegular language‚Äô coined by Stephen Kleene. \n\n\n\n\n\n\nThey started as a representation of more complex diagrams used in the field and in theoretical linguistics. \n\n\n\n\n\n\nIn the late 60‚Äôs they started to be implemented in text processors, being ed one of the most popular at the time. This was followed by vi, AWK, Emacs the next decade.\nThen in the 80‚Äôs‚Ä¶ PERL happened‚Ä¶ And it‚Äôs dominance for language processing is still at large.\n\n\n\n\n\n\n\n\nUse of regular expressions\nText search and manipulation in editors and IDEs (e.g., VSCode, Sublime Text).\nData validation (emails, phone numbers).\nLog file parsing and monitoring.\nWeb scraping and data extraction.\nProgramming languages: Python, R, Perl, JavaScript, and many more.\nCommand-line tools and shell scripting for automation.\n\n\nRegular expressions in bioinformatics\nFile parsing & data extraction:\nFASTA/FASTQ file processing: extracting headers, filtering sequences.\nGFF/GTF annotation files: extracting gene features.\nVCF (Variant Call Format) files: parsing variant info fields.\nSequence pattern searching:\nMotif detection (e.g., promoter elements, restriction sites).\nDetecting ambiguous nucleotide codes.\nData cleaning: standardizing metadata fields in sequencing experiment descriptions.\nRegular expressions can also be used in R. Let‚Äôs explore its potential."
  },
  {
    "objectID": "Week3/week3_part2.html#grep",
    "href": "Week3/week3_part2.html#grep",
    "title": "Regular expressions",
    "section": "grep",
    "text": "grep\nGrep is the most common name for matching patterns with regex. It exists just as grep in base R but be aware that there are many variants of it.\n\nWhat does grep mean?\ng/re/p meaning ‚ÄúGlobal search for Regular Expression and Print matching lines‚Äù\n\n\nHow to use it?\n\ngrep(\"pattern\", YourStringOfInterest)\n\n\n\nPlay with it!\n\n#grep(, )\n\n\n\nLet‚Äôs get some data.\n\nreg.exmpl <- c(\"krava\", \"plava\", \"prava\", \"plavac\",\"tava\", \"vatra\", \"bla\", \"blabla\", \"blablabla\", \n               \"abcabcabc\", \"abcblaabc\", \"blaXblaX\", \"abcYabc\", \"abc1z\", \"abc4z\",\"plllava\",\n               \"pava\", \"XX\",\"XnblaX\")\n\nProblem: We want to find all words that contain the substring ‚Äúva‚Äù.\n\n\n\nWe are just getting their position in the subject array. if you want grep to print the elements that matched you will need to add value = TRUE"
  },
  {
    "objectID": "Week3/week3_part2.html#anchors",
    "href": "Week3/week3_part2.html#anchors",
    "title": "Regular expressions",
    "section": "Anchors",
    "text": "Anchors\n^ $: Starting or ending with substring\n\n\n [1] \"krava\"     \"plava\"     \"prava\"     \"plavac\"    \"tava\"      \"vatra\"    \n [7] \"bla\"       \"blabla\"    \"blablabla\" \"abcabcabc\" \"abcblaabc\" \"blaXblaX\" \n[13] \"abcYabc\"   \"abc1z\"     \"abc4z\"     \"plllava\"   \"pava\"      \"XX\"       \n[19] \"XnblaX\"   \n\n\nSymbol ^ represents beginning of the string:\n\ngrep(\"^va\", reg.exmpl, value=T)\n\n[1] \"vatra\"\n\n\nSymbol $ represents end of the string:\n\ngrep(\"ra$\", reg.exmpl, value=T)\n\n[1] \"vatra\"\n\n\n\nGet all the words that contain the substring ‚Äúbla‚Äù.\n\n\n\n\n\nGet all the words that START with substring ‚Äúbla‚Äù.\n\n\n\n\n\n\nGet all the words that END with substring ‚Äúbla‚Äù."
  },
  {
    "objectID": "Week3/week3_part2.html#wildcards",
    "href": "Week3/week3_part2.html#wildcards",
    "title": "Regular expressions",
    "section": "Wildcards",
    "text": "Wildcards\nWe want to find all words that look like: ‚Äúp‚Äù followed by any one character, followed by ‚Äúava‚Äù.\nIn our case this would be plava, prava.\nWhen we are not sure of which character we expect, we can just write . instead of that character.\nGo ahead!\n\n\n\nThere are many more WILDCARD characters, some of them are to represent things as any digit or any letter. You‚Äôll need to check for your homework.\n\nRestrict your options\nIf we want to find words containing lava or tava as a substring, we can write that as:\n\ngrep(\"[lt]ava\", reg.exmpl, value=T)\n\n[1] \"plava\"   \"plavac\"  \"tava\"    \"plllava\"\n\n\nHere, [lt] represents ONE character - either l or t in this position. Sets of characters enclosed in square brackets [] are called character classes. The pattern will match any single character that belongs to that set."
  },
  {
    "objectID": "Week3/week3_part2.html#quantification-characters",
    "href": "Week3/week3_part2.html#quantification-characters",
    "title": "Regular expressions",
    "section": "Quantification Characters",
    "text": "Quantification Characters\nWhen we don‚Äôt know the number of occurrences of some character, we can use special symbols to describe what we expect:\n? - zero or one  + - one or more  * - zero or more \n\nlll <- c(\"Eample1\",\"Example1\", \"Exxample1\", \"Exxxample1\")\nlll\n\n[1] \"Eample1\"    \"Example1\"   \"Exxample1\"  \"Exxxample1\"\n\n\nFor example:\n\ngrep(\"Ex?ample1\", lll, value = T)\n\n[1] \"Eample1\"  \"Example1\"\n\ngrep(\"Ex+ample1\", lll, value = T)\n\n[1] \"Example1\"   \"Exxample1\"  \"Exxxample1\"\n\ngrep(\"Ex*ample1\", lll, value = T)\n\n[1] \"Eample1\"    \"Example1\"   \"Exxample1\"  \"Exxxample1\"\n\n\nWhen we know the number of occurrences of some character, we can use this:\n{n} - this symbol appears here exactly n times in a row\n{n, m} - this symbol appears here from n to m times in a row\nWhat do you expect to get now?\n\ngrep(\"x{2}\", lll, value = T)\n\n[1] \"Exxample1\"  \"Exxxample1\"\n\n\n\ngrep(\"x{0,2}\", lll, value = T)\n\n[1] \"Eample1\"    \"Example1\"   \"Exxample1\"  \"Exxxample1\"\n\n\n\ngrep(\"x{2}a\", lll, value = T)\n\n[1] \"Exxample1\"  \"Exxxample1\"\n\n\n\ngrep(\"Ex{2}a\", lll, value = T)\n\n[1] \"Exxample1\""
  },
  {
    "objectID": "Week3/week3_part2.html#special-characters",
    "href": "Week3/week3_part2.html#special-characters",
    "title": "Regular expressions",
    "section": "Special Characters",
    "text": "Special Characters\nWhat if we want to find ‚Äú?‚Äù?\nLook at the following example:\n\nprimjer2 <- c(\"How\",\"to\", \"find \", \"a\", \"question\", \"mark?\")\nprimjer2\n\n[1] \"How\"      \"to\"       \"find \"    \"a\"        \"question\" \"mark?\"   \n\n\nSince ? is a special character, if we try to use it like this:\n\ngrep(\"?\", primjer2,value=T)\n\n[1] \"How\"      \"to\"       \"find \"    \"a\"        \"question\" \"mark?\"   \n\n\nWe wont get what we want. We use ‚Äú‚Äù to tell grep that we want the real sign and not the special ability of that sign!\n\ngrep(\"\\\\?\", primjer2,value=T)\n\n[1] \"mark?\""
  },
  {
    "objectID": "Week3/week3_part2.html#exclude-characters",
    "href": "Week3/week3_part2.html#exclude-characters",
    "title": "Regular expressions",
    "section": "Exclude characters",
    "text": "Exclude characters\nIf you want to find a character that is NOT some character, use ‚Äú[^ ]‚Äù\n\nreg.exmpl\n\n [1] \"krava\"     \"plava\"     \"prava\"     \"plavac\"    \"tava\"      \"vatra\"    \n [7] \"bla\"       \"blabla\"    \"blablabla\" \"abcabcabc\" \"abcblaabc\" \"blaXblaX\" \n[13] \"abcYabc\"   \"abc1z\"     \"abc4z\"     \"plllava\"   \"pava\"      \"XX\"       \n[19] \"XnblaX\"   \n\n\n\ngrep(\".ava\", reg.exmpl, value = T)\n\n[1] \"krava\"   \"plava\"   \"prava\"   \"plavac\"  \"tava\"    \"plllava\" \"pava\"   \n\ngrep(\"[^l]ava\", reg.exmpl, value = T)\n\n[1] \"krava\" \"prava\" \"tava\"  \"pava\""
  },
  {
    "objectID": "Week3/week3_part2.html#groups",
    "href": "Week3/week3_part2.html#groups",
    "title": "Regular expressions",
    "section": "Groups",
    "text": "Groups\nWhen we want to find groups of characters, we can do it like this:\n\nprimjer <- c(\"GRP1\", \"GRP2\", \"GRP3\",\"GRP1GRP2\", \"GRP1GRP3\", \"GRP2GRP3\", \"GRP1GRP1GRP2\", \"GRP1GRP1GRP3\", \"GRP1GRP2GRP3\",\"GRP2GRP3\",\"GRP2GRP1GRP2\", \"GRP2GRP1GRP3\", \"GRP2GRP2GRP3\", \"GRP3GRP1GRP2\", \"GRP3GRP1GRP3\", \"GRP3GRP2GRP3\", \"GRP1GRP2GRP1GRP3\", \"GRP1GRP2GRP2GRP3\", \"GRP1GRP3GRP2GRP3\")\nprimjer <- sort(unique(primjer))\nprimjer\n\n [1] \"GRP1\"             \"GRP1GRP1GRP2\"     \"GRP1GRP1GRP3\"     \"GRP1GRP2\"        \n [5] \"GRP1GRP2GRP1GRP3\" \"GRP1GRP2GRP2GRP3\" \"GRP1GRP2GRP3\"     \"GRP1GRP3\"        \n [9] \"GRP1GRP3GRP2GRP3\" \"GRP2\"             \"GRP2GRP1GRP2\"     \"GRP2GRP1GRP3\"    \n[13] \"GRP2GRP2GRP3\"     \"GRP2GRP3\"         \"GRP3\"             \"GRP3GRP1GRP2\"    \n[17] \"GRP3GRP1GRP3\"     \"GRP3GRP2GRP3\"    \n\n\nIf we want to work on a group of characters, put them in round brackets!\nAll words where ‚ÄúGRP1‚Äù is repeated 2 times in a row:\n\ngrep(\"(GRP1){2}\", primjer, value=T)\n\n[1] \"GRP1GRP1GRP2\" \"GRP1GRP1GRP3\"\n\n\nAll words where ‚ÄúGRP1‚Äù is repeated 1 or more times before GRP2 :\n\ngrep(\"(GRP1)+(GRP2)\", primjer, value=T)\n\n[1] \"GRP1GRP1GRP2\"     \"GRP1GRP2\"         \"GRP1GRP2GRP1GRP3\" \"GRP1GRP2GRP2GRP3\"\n[5] \"GRP1GRP2GRP3\"     \"GRP2GRP1GRP2\"     \"GRP3GRP1GRP2\""
  },
  {
    "objectID": "Week3/week3_part2.html#boolean-operators",
    "href": "Week3/week3_part2.html#boolean-operators",
    "title": "Regular expressions",
    "section": "Boolean operators",
    "text": "Boolean operators\nOR (|): Matches either pattern on its left or right. P2 matches ‚ÄúP1‚Äù or ‚ÄúP2‚Äù."
  },
  {
    "objectID": "Week3/week3_part2.html#functions-that-use-regular-expressions",
    "href": "Week3/week3_part2.html#functions-that-use-regular-expressions",
    "title": "Regular expressions",
    "section": "Functions that use regular expressions",
    "text": "Functions that use regular expressions\ngrepl(pattern, x): Returns TRUE/FALSE if pattern found\ngrep(pattern, x): Returns indices of matches\nregexpr(pattern, x): Returns position of first match\ngregexpr(pattern, x): Positions of all matches\nsub(pattern, replacement, x): Replace first match\ngsub(pattern, replacement, x): Replace all matches\n\nExample 1: Finding GC dinucleotides with grepl()\n\nseq <- c(\"ATGCGTA\", \"CGTTGA\", \"ATATAT\", \"GCGCGC\")\n# Find sequences with CG dinucleotide\ngrepl(\"CG\", seq)\n\n[1]  TRUE  TRUE FALSE  TRUE\n\n# [1] TRUE TRUE FALSE TRUE\n\nExample 2: Transcribing DNA to mRNA with gsub()\n\ndna_seq <- \"ATGCGTACGTTAG\"\n\n# Replace all 'T' with 'U' using gsub for full transcription\nmrna_seq <- gsub(\"T\", \"U\", dna_seq)\n\nprint(mrna_seq)\n\n[1] \"AUGCGUACGUUAG\"\n\n# Output: \"AUGCGUACGUUAG\"\n\nExample 3: Finding the Position of a Transcription Factor (TF) Binding Site with regexpr()\n\ndna_seq <- \"GCGTATATAGCGCGTATAAGT\"\n\n# Find position of first TATA box using regexpr\npos <- regexpr(\"TATA\", dna_seq)\n\nprint(pos)          # Starting position of first match\n\n[1] 4\nattr(,\"match.length\")\n[1] 4\nattr(,\"index.type\")\n[1] \"chars\"\nattr(,\"useBytes\")\n[1] TRUE\n\nprint(attr(pos, \"match.length\"))  # Length of the match\n\n[1] 4\n\n# Extract the matched sequence\nbinding_site <- regmatches(dna_seq, pos)\nprint(binding_site)  # Should print \"TATA\"\n\n[1] \"TATA\""
  },
  {
    "objectID": "Week3/week3_part2.html#exercises",
    "href": "Week3/week3_part2.html#exercises",
    "title": "Regular expressions",
    "section": "Exercises",
    "text": "Exercises\n\nFind all sequences starting with ATG and followed by any three nucleotides.\n\n\nseqs <- c(\"ATGAAA\", \"ATGCCC\", \"ATG\", \"GGGATG\")\n# Your code here\n\n\nExtract all stretches of exactly three or four A‚Äôs (A{3,4}) in the following DNA sequences.\n\n\nseqs <- c(\"AAATTT\", \"AAAAT\", \"AAAAA\", \"TTTAAAG\")\n# Your code here\n\n\nReplace the first stretch of G‚Äôs (one or more) with X in the following sequences.\n\n\nseqs <- c(\"GGATGC\", \"GGAAGG\", \"AGGCGG\")\n# Your code here\n\n\nCheck which sequences contain any character other than A, T, C, or G (e.g., ambiguous nucleotide N).\n\n\nseqs <- c(\"ATGCN\", \"GGCCA\", \"TTANT\")\n# Your code here\n\n\nFind sequences ending with a stop codon (TAA, TAG, or TGA).\n\n\nseqs <- c(\"ATGCCCTAA\", \"ATGCCCTAG\", \"ATGCCCTGA\", \"ATGCCC\")\n# Your code here"
  }
]